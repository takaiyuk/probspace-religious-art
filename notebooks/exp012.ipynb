{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c359c42d-0550-4236-9b24-1ba0a9ac7e73",
   "metadata": {},
   "source": [
    "- base version: exp008\n",
    "- add: resnext50, more augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90eab5f1-927b-4820-b258-ea8f791a4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17908034-de36-4913-8e43-b3b8a21932b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train_images: str = f\"{_prefix}/christ-train-imgs.npz\"\n",
    "    train_labels: str = f\"{_prefix}/christ-train-labels.npz\"\n",
    "    test_images: str = f\"{_prefix}/christ-test-imgs.npz\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp012\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-5\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    model_name: str = \"resnext50_32x4d\"\n",
    "    batch_size: int = 16\n",
    "    test_batch_size: int = 128\n",
    "    epochs: int = 3 if Basic.is_debug else 100\n",
    "    image_size: int = 384\n",
    "    num_workers: int = 0\n",
    "    target_size: int = 13\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = True\n",
    "    num_aug: int = 10\n",
    "    num_tta: int = 10\n",
    "    early_stopping_rounds: int = 20\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model):\n",
    "#     if x.startswith(f\"{Basic.run_name}_\"):\n",
    "#         os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_npz(path: str) -> np.array:\n",
    "    x = np.load(path)[\"arr_0\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class ProbSpaceDataset(data.Dataset):\n",
    "    def __init__(self, images: np.array, labels: Optional[np.array] = None, is_train: bool = True) -> None:\n",
    "        \"\"\"images.shape: (b, h, w, c), labels: (b,)\"\"\"\n",
    "        assert (is_train and labels is not None) or (not is_train and labels is None)        \n",
    "        self.is_train = is_train\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.Resize(size),\n",
    "            ]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.ToPILImage(),\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        image = self.images[index]\n",
    "        image = self.transformer(image)\n",
    "        if self.is_train:\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            label = -1\n",
    "        return {\"image\": image, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d403d8d-cd02-4fca-9c31-a32cdfbc7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ProbSpaceModel(nn.Module):\n",
    "    def __init__(self, model_config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_config.params.model_name, \n",
    "            pretrained=model_config.params.pretrained, \n",
    "            num_classes=model_config.params.target_size,\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_model(model_config: ModelConfig):\n",
    "    model = ProbSpaceModel(model_config)\n",
    "    model.to(model_config.basic.device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import Counter, OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array, verbose: bool = False) -> float:\n",
    "        score = metrics.accuracy_score(y_true, y_pred)\n",
    "        if verbose:\n",
    "            print(f\"Score: {score:<.5f}\")\n",
    "        return score\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_epoch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        for _ in range(self.cfg.params.num_aug):\n",
    "            for step, image_label_dict in enumerate(train_loader):\n",
    "                images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "                labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_epoch(self, valid_loader, model, criterion):\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds).reshape(-1, self.params.target_size)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int) -> pd.DataFrame:\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        train_images = load_npz(InputPath.train_images)\n",
    "        train_labels = load_npz(InputPath.train_labels)        \n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index.tolist()\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index.tolist()\n",
    "        train_images_folds = train_images[trn_idx]\n",
    "        valid_images_folds = train_images[val_idx]\n",
    "        train_labels_folds = train_labels[trn_idx]\n",
    "        valid_labels_folds = train_labels[val_idx]\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = ProbSpaceDataset(\n",
    "            train_images_folds,\n",
    "            train_labels_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = ProbSpaceDataset(\n",
    "            valid_images_folds,\n",
    "            valid_labels_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # 少数クラスほど重みをつける\n",
    "        weights = 1 / np.array([Counter(train_labels_folds)[i] for i in range(self.params.target_size)])\n",
    "        weights = weights / np.sum(weights)\n",
    "        assert np.all(weights != 0) \n",
    "        weights = torch.tensor(weights).float().to(self.cfg.basic.device)\n",
    "\n",
    "        model = build_model(model_config=self.cfg)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        best_model = None\n",
    "        best_preds = None\n",
    "        best_score = 0\n",
    "        scores: List[float] = []\n",
    "        num_not_improved = 0\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_epoch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_array = np.zeros((num_times_tta, len(val_idx), self.params.target_size))\n",
    "            for i in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_epoch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_array[i] = preds\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "\n",
    "            preds = preds_array.mean(axis=0)\n",
    "            preds_ = np.argmax(preds, axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            score = self._evaluate(valid_labels, preds_)\n",
    "            scores.append(score)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "            if score > best_score:\n",
    "                best_model = model\n",
    "                best_preds = preds\n",
    "                best_score = score\n",
    "                num_not_improved = 0\n",
    "            else:\n",
    "                num_not_improved += 1\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "            if self.params.early_stopping_rounds > 0 and self.params.early_stopping_rounds == num_not_improved:\n",
    "                print(f\"Early stopping break: not improved {num_not_improved} times in a row\")\n",
    "                break\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": best_model.state_dict(), \n",
    "                \"preds\": best_preds, \n",
    "                \"best_score\": best_score, \n",
    "                \"scores\": scores\n",
    "            },\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "        )\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = np.argmax(check_point[\"preds\"], axis=1)\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"], verbose=True)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"], verbose=True)\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_epoch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds).reshape(-1, self.params.target_size)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_images = load_npz(input_path.test_images)\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "        \n",
    "        test_dataset = ProbSpaceDataset(\n",
    "            test_images,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        # preds = self._test_epoch(test_loader, model)\n",
    "        preds_array = np.zeros((num_times_tta, len(test_images), self.params.target_size))\n",
    "        for i in range(num_times_tta):\n",
    "            _preds = self._test_epoch(test_loader, model)\n",
    "            preds_array[i] = _preds\n",
    "        preds = preds_array.mean(axis=0)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        test_images = load_npz(input_path.test_images)\n",
    "        df_sub = pd.DataFrame({\"id\": list(range(len(test_images)))})\n",
    "        df_sub = df_sub.assign(y=preds)\n",
    "        print(df_sub.head())\n",
    "        df_sub = df_sub.astype(int)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame = None) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.mean(preds, axis=0)\n",
    "        assert preds_mean.shape == (497, 13)\n",
    "        preds_mean = preds_mean.argmax(axis=1)\n",
    "        assert preds_mean.shape == (497,)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = load_npz(InputPath.train_labels)\n",
    "\n",
    "train = pd.DataFrame({\"target\": train_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [1 2 3 6 7]~[645 646 648 651 653] (523)\t[ 0  4  5 11 17]~[644 647 649 650 652] (131)\n",
      "fold: 1 - [0 1 2 4 5]~[649 650 651 652 653] (523)\t[ 3  6  8  9 12]~[636 638 641 645 648] (131)\n",
      "fold: 2 - [0 1 3 4 5]~[649 650 651 652 653] (523)\t[ 2 13 14 18 21]~[629 631 632 633 646] (131)\n",
      "fold: 3 - [0 2 3 4 5]~[648 649 650 651 652] (523)\t[ 1 10 15 16 27]~[611 614 628 639 653] (131)\n",
      "fold: 4 - [0 1 2 3 4]~[648 649 650 652 653] (524)\t[ 7 22 23 24 25]~[622 635 637 643 651] (130)\n"
     ]
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]} ({len(tr_idx)})\\t{val_idx[:5]}~{val_idx[-5:]} ({len(val_idx)})\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "# if model_config.kfold.method == \"skf\":\n",
    "#     pd.set_option(\"display.max_rows\", 65)\n",
    "#     display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7747e0-4b47-4f29-9555-80495b4adffd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode: False\n",
      "start time: 2021-08-09 18:08:06.550704\n",
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 2.5423  avg_val_loss: 2.5375  time: 129s\n",
      "Epoch 1 - Accuracy: 0.16793893129770993\n",
      "Epoch 1 - Best Score: 0.1679\n",
      "Epoch 2 - avg_train_loss: 2.4512  avg_val_loss: 2.4771  time: 129s\n",
      "Epoch 2 - Accuracy: 0.20610687022900764\n",
      "Epoch 2 - Best Score: 0.2061\n",
      "Epoch 3 - avg_train_loss: 2.3432  avg_val_loss: 2.4262  time: 129s\n",
      "Epoch 3 - Accuracy: 0.2748091603053435\n",
      "Epoch 3 - Best Score: 0.2748\n",
      "Epoch 4 - avg_train_loss: 2.2422  avg_val_loss: 2.3711  time: 129s\n",
      "Epoch 4 - Accuracy: 0.37404580152671757\n",
      "Epoch 4 - Best Score: 0.3740\n",
      "Epoch 5 - avg_train_loss: 2.1565  avg_val_loss: 2.3370  time: 129s\n",
      "Epoch 5 - Accuracy: 0.4351145038167939\n",
      "Epoch 5 - Best Score: 0.4351\n",
      "Epoch 6 - avg_train_loss: 2.1024  avg_val_loss: 2.3270  time: 129s\n",
      "Epoch 6 - Accuracy: 0.4961832061068702\n",
      "Epoch 6 - Best Score: 0.4962\n",
      "Epoch 7 - avg_train_loss: 2.0407  avg_val_loss: 2.3120  time: 129s\n",
      "Epoch 7 - Accuracy: 0.549618320610687\n",
      "Epoch 7 - Best Score: 0.5496\n",
      "Epoch 8 - avg_train_loss: 1.9852  avg_val_loss: 2.3119  time: 129s\n",
      "Epoch 8 - Accuracy: 0.5114503816793893\n",
      "Epoch 8 - Best Score: 0.5496\n",
      "Epoch 9 - avg_train_loss: 1.9365  avg_val_loss: 2.2889  time: 129s\n",
      "Epoch 9 - Accuracy: 0.549618320610687\n",
      "Epoch 9 - Best Score: 0.5496\n",
      "Epoch 10 - avg_train_loss: 1.8943  avg_val_loss: 2.2899  time: 129s\n",
      "Epoch 10 - Accuracy: 0.5419847328244275\n",
      "Epoch 10 - Best Score: 0.5496\n",
      "Epoch 11 - avg_train_loss: 1.8745  avg_val_loss: 2.2833  time: 129s\n",
      "Epoch 11 - Accuracy: 0.5419847328244275\n",
      "Epoch 11 - Best Score: 0.5496\n",
      "Epoch 12 - avg_train_loss: 1.8541  avg_val_loss: 2.2870  time: 129s\n",
      "Epoch 12 - Accuracy: 0.5419847328244275\n",
      "Epoch 12 - Best Score: 0.5496\n",
      "Epoch 13 - avg_train_loss: 1.8327  avg_val_loss: 2.2966  time: 129s\n",
      "Epoch 13 - Accuracy: 0.5190839694656488\n",
      "Epoch 13 - Best Score: 0.5496\n",
      "Epoch 14 - avg_train_loss: 1.8163  avg_val_loss: 2.3065  time: 129s\n",
      "Epoch 14 - Accuracy: 0.5267175572519084\n",
      "Epoch 14 - Best Score: 0.5496\n",
      "Epoch 15 - avg_train_loss: 1.8118  avg_val_loss: 2.2843  time: 129s\n",
      "Epoch 15 - Accuracy: 0.5572519083969466\n",
      "Epoch 15 - Best Score: 0.5573\n",
      "Epoch 16 - avg_train_loss: 1.7973  avg_val_loss: 2.2788  time: 129s\n",
      "Epoch 16 - Accuracy: 0.5572519083969466\n",
      "Epoch 16 - Best Score: 0.5573\n",
      "Epoch 17 - avg_train_loss: 1.7847  avg_val_loss: 2.2955  time: 129s\n",
      "Epoch 17 - Accuracy: 0.5419847328244275\n",
      "Epoch 17 - Best Score: 0.5573\n",
      "Epoch 18 - avg_train_loss: 1.7796  avg_val_loss: 2.2969  time: 129s\n",
      "Epoch 18 - Accuracy: 0.5190839694656488\n",
      "Epoch 18 - Best Score: 0.5573\n",
      "Epoch 19 - avg_train_loss: 1.7733  avg_val_loss: 2.2786  time: 129s\n",
      "Epoch 19 - Accuracy: 0.5267175572519084\n",
      "Epoch 19 - Best Score: 0.5573\n",
      "Epoch 20 - avg_train_loss: 1.7652  avg_val_loss: 2.2890  time: 129s\n",
      "Epoch 20 - Accuracy: 0.5572519083969466\n",
      "Epoch 20 - Best Score: 0.5573\n",
      "Epoch 21 - avg_train_loss: 1.7661  avg_val_loss: 2.2939  time: 129s\n",
      "Epoch 21 - Accuracy: 0.549618320610687\n",
      "Epoch 21 - Best Score: 0.5573\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 22 - avg_train_loss: 1.7615  avg_val_loss: 2.2998  time: 129s\n",
      "Epoch 22 - Accuracy: 0.5343511450381679\n",
      "Epoch 22 - Best Score: 0.5573\n",
      "Epoch 23 - avg_train_loss: 1.7552  avg_val_loss: 2.3004  time: 129s\n",
      "Epoch 23 - Accuracy: 0.5572519083969466\n",
      "Epoch 23 - Best Score: 0.5573\n",
      "Epoch 24 - avg_train_loss: 1.7558  avg_val_loss: 2.2903  time: 129s\n",
      "Epoch 24 - Accuracy: 0.5648854961832062\n",
      "Epoch 24 - Best Score: 0.5649\n",
      "Epoch 25 - avg_train_loss: 1.7617  avg_val_loss: 2.2892  time: 129s\n",
      "Epoch 25 - Accuracy: 0.5648854961832062\n",
      "Epoch 25 - Best Score: 0.5649\n",
      "Epoch 26 - avg_train_loss: 1.7586  avg_val_loss: 2.2806  time: 129s\n",
      "Epoch 26 - Accuracy: 0.5725190839694656\n",
      "Epoch 26 - Best Score: 0.5725\n",
      "Epoch 27 - avg_train_loss: 1.7520  avg_val_loss: 2.2993  time: 130s\n",
      "Epoch 27 - Accuracy: 0.5419847328244275\n",
      "Epoch 27 - Best Score: 0.5725\n",
      "Epoch 28 - avg_train_loss: 1.7507  avg_val_loss: 2.2758  time: 129s\n",
      "Epoch 28 - Accuracy: 0.5801526717557252\n",
      "Epoch 28 - Best Score: 0.5802\n",
      "Epoch 29 - avg_train_loss: 1.7519  avg_val_loss: 2.2736  time: 129s\n",
      "Epoch 29 - Accuracy: 0.5801526717557252\n",
      "Epoch 29 - Best Score: 0.5802\n",
      "Epoch 30 - avg_train_loss: 1.7514  avg_val_loss: 2.2825  time: 129s\n",
      "Epoch 30 - Accuracy: 0.5801526717557252\n",
      "Epoch 30 - Best Score: 0.5802\n",
      "Epoch 31 - avg_train_loss: 1.7475  avg_val_loss: 2.2807  time: 129s\n",
      "Epoch 31 - Accuracy: 0.5725190839694656\n",
      "Epoch 31 - Best Score: 0.5802\n",
      "Epoch 32 - avg_train_loss: 1.7551  avg_val_loss: 2.2882  time: 129s\n",
      "Epoch 32 - Accuracy: 0.5419847328244275\n",
      "Epoch 32 - Best Score: 0.5802\n",
      "Epoch 33 - avg_train_loss: 1.7531  avg_val_loss: 2.2799  time: 129s\n",
      "Epoch 33 - Accuracy: 0.549618320610687\n",
      "Epoch 33 - Best Score: 0.5802\n",
      "Epoch 34 - avg_train_loss: 1.7532  avg_val_loss: 2.2746  time: 129s\n",
      "Epoch 34 - Accuracy: 0.5801526717557252\n",
      "Epoch 34 - Best Score: 0.5802\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 35 - avg_train_loss: 1.7551  avg_val_loss: 2.2967  time: 129s\n",
      "Epoch 35 - Accuracy: 0.5419847328244275\n",
      "Epoch 35 - Best Score: 0.5802\n",
      "Epoch 36 - avg_train_loss: 1.7584  avg_val_loss: 2.2673  time: 129s\n",
      "Epoch 36 - Accuracy: 0.5648854961832062\n",
      "Epoch 36 - Best Score: 0.5802\n",
      "Epoch 37 - avg_train_loss: 1.7492  avg_val_loss: 2.2896  time: 129s\n",
      "Epoch 37 - Accuracy: 0.5877862595419847\n",
      "Epoch 37 - Best Score: 0.5878\n",
      "Epoch 38 - avg_train_loss: 1.7574  avg_val_loss: 2.2851  time: 129s\n",
      "Epoch 38 - Accuracy: 0.5419847328244275\n",
      "Epoch 38 - Best Score: 0.5878\n",
      "Epoch 39 - avg_train_loss: 1.7510  avg_val_loss: 2.2978  time: 129s\n",
      "Epoch 39 - Accuracy: 0.5267175572519084\n",
      "Epoch 39 - Best Score: 0.5878\n",
      "Epoch 40 - avg_train_loss: 1.7490  avg_val_loss: 2.2793  time: 129s\n",
      "Epoch 40 - Accuracy: 0.5648854961832062\n",
      "Epoch 40 - Best Score: 0.5878\n",
      "Epoch 41 - avg_train_loss: 1.7475  avg_val_loss: 2.2903  time: 129s\n",
      "Epoch 41 - Accuracy: 0.5267175572519084\n",
      "Epoch 41 - Best Score: 0.5878\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 42 - avg_train_loss: 1.7484  avg_val_loss: 2.2744  time: 129s\n",
      "Epoch 42 - Accuracy: 0.549618320610687\n",
      "Epoch 42 - Best Score: 0.5878\n",
      "Epoch 43 - avg_train_loss: 1.7481  avg_val_loss: 2.2866  time: 129s\n",
      "Epoch 43 - Accuracy: 0.5725190839694656\n",
      "Epoch 43 - Best Score: 0.5878\n",
      "Epoch 44 - avg_train_loss: 1.7484  avg_val_loss: 2.2884  time: 129s\n",
      "Epoch 44 - Accuracy: 0.5648854961832062\n",
      "Epoch 44 - Best Score: 0.5878\n",
      "Epoch 45 - avg_train_loss: 1.7514  avg_val_loss: 2.2855  time: 129s\n",
      "Epoch 45 - Accuracy: 0.5419847328244275\n",
      "Epoch 45 - Best Score: 0.5878\n",
      "Epoch 46 - avg_train_loss: 1.7493  avg_val_loss: 2.2847  time: 129s\n",
      "Epoch 46 - Accuracy: 0.549618320610687\n",
      "Epoch 46 - Best Score: 0.5878\n",
      "Epoch 47 - avg_train_loss: 1.7517  avg_val_loss: 2.2821  time: 129s\n",
      "Epoch 47 - Accuracy: 0.5648854961832062\n",
      "Epoch 47 - Best Score: 0.5878\n",
      "Epoch 48 - avg_train_loss: 1.7463  avg_val_loss: 2.2761  time: 129s\n",
      "Epoch 48 - Accuracy: 0.5343511450381679\n",
      "Epoch 48 - Best Score: 0.5878\n",
      "Epoch 49 - avg_train_loss: 1.7508  avg_val_loss: 2.2790  time: 129s\n",
      "Epoch 49 - Accuracy: 0.549618320610687\n",
      "Epoch 49 - Best Score: 0.5878\n",
      "Epoch 50 - avg_train_loss: 1.7516  avg_val_loss: 2.2815  time: 129s\n",
      "Epoch 50 - Accuracy: 0.549618320610687\n",
      "Epoch 50 - Best Score: 0.5878\n",
      "Epoch 51 - avg_train_loss: 1.7480  avg_val_loss: 2.2927  time: 129s\n",
      "Epoch 51 - Accuracy: 0.5725190839694656\n",
      "Epoch 51 - Best Score: 0.5878\n",
      "Epoch 52 - avg_train_loss: 1.7504  avg_val_loss: 2.2835  time: 129s\n",
      "Epoch 52 - Accuracy: 0.5572519083969466\n",
      "Epoch 52 - Best Score: 0.5878\n",
      "Epoch 53 - avg_train_loss: 1.7556  avg_val_loss: 2.2834  time: 129s\n",
      "Epoch 53 - Accuracy: 0.5801526717557252\n",
      "Epoch 53 - Best Score: 0.5878\n",
      "Epoch 54 - avg_train_loss: 1.7465  avg_val_loss: 2.2857  time: 129s\n",
      "Epoch 54 - Accuracy: 0.549618320610687\n",
      "Epoch 54 - Best Score: 0.5878\n",
      "Epoch 55 - avg_train_loss: 1.7439  avg_val_loss: 2.2758  time: 129s\n",
      "Epoch 55 - Accuracy: 0.5648854961832062\n",
      "Epoch 55 - Best Score: 0.5878\n",
      "Epoch 56 - avg_train_loss: 1.7539  avg_val_loss: 2.2680  time: 129s\n",
      "Epoch 56 - Accuracy: 0.5572519083969466\n",
      "Epoch 56 - Best Score: 0.5878\n",
      "Epoch 57 - avg_train_loss: 1.7512  avg_val_loss: 2.2900  time: 129s\n",
      "Epoch 57 - Accuracy: 0.5801526717557252\n",
      "Epoch 57 - Best Score: 0.5878\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.58779\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 2.5506  avg_val_loss: 2.5377  time: 129s\n",
      "Epoch 1 - Accuracy: 0.22900763358778625\n",
      "Epoch 1 - Best Score: 0.2290\n",
      "Epoch 2 - avg_train_loss: 2.4363  avg_val_loss: 2.4370  time: 129s\n",
      "Epoch 2 - Accuracy: 0.31297709923664124\n",
      "Epoch 2 - Best Score: 0.3130\n",
      "Epoch 3 - avg_train_loss: 2.3007  avg_val_loss: 2.3874  time: 129s\n",
      "Epoch 3 - Accuracy: 0.4351145038167939\n",
      "Epoch 3 - Best Score: 0.4351\n",
      "Epoch 4 - avg_train_loss: 2.2081  avg_val_loss: 2.3573  time: 129s\n",
      "Epoch 4 - Accuracy: 0.44274809160305345\n",
      "Epoch 4 - Best Score: 0.4427\n",
      "Epoch 5 - avg_train_loss: 2.1239  avg_val_loss: 2.3173  time: 129s\n",
      "Epoch 5 - Accuracy: 0.48091603053435117\n",
      "Epoch 5 - Best Score: 0.4809\n",
      "Epoch 6 - avg_train_loss: 2.0505  avg_val_loss: 2.3085  time: 129s\n",
      "Epoch 6 - Accuracy: 0.5267175572519084\n",
      "Epoch 6 - Best Score: 0.5267\n",
      "Epoch 7 - avg_train_loss: 1.9992  avg_val_loss: 2.3115  time: 129s\n",
      "Epoch 7 - Accuracy: 0.5190839694656488\n",
      "Epoch 7 - Best Score: 0.5267\n",
      "Epoch 8 - avg_train_loss: 1.9467  avg_val_loss: 2.2775  time: 129s\n",
      "Epoch 8 - Accuracy: 0.5267175572519084\n",
      "Epoch 8 - Best Score: 0.5267\n",
      "Epoch 9 - avg_train_loss: 1.9150  avg_val_loss: 2.2658  time: 129s\n",
      "Epoch 9 - Accuracy: 0.5725190839694656\n",
      "Epoch 9 - Best Score: 0.5725\n",
      "Epoch 10 - avg_train_loss: 1.8863  avg_val_loss: 2.2834  time: 129s\n",
      "Epoch 10 - Accuracy: 0.549618320610687\n",
      "Epoch 10 - Best Score: 0.5725\n",
      "Epoch 11 - avg_train_loss: 1.8628  avg_val_loss: 2.2662  time: 129s\n",
      "Epoch 11 - Accuracy: 0.5343511450381679\n",
      "Epoch 11 - Best Score: 0.5725\n",
      "Epoch 12 - avg_train_loss: 1.8500  avg_val_loss: 2.2689  time: 129s\n",
      "Epoch 12 - Accuracy: 0.5267175572519084\n",
      "Epoch 12 - Best Score: 0.5725\n",
      "Epoch 13 - avg_train_loss: 1.8361  avg_val_loss: 2.2692  time: 129s\n",
      "Epoch 13 - Accuracy: 0.5419847328244275\n",
      "Epoch 13 - Best Score: 0.5725\n",
      "Epoch 14 - avg_train_loss: 1.8281  avg_val_loss: 2.2707  time: 130s\n",
      "Epoch 14 - Accuracy: 0.5190839694656488\n",
      "Epoch 14 - Best Score: 0.5725\n",
      "Epoch 15 - avg_train_loss: 1.8172  avg_val_loss: 2.2623  time: 130s\n",
      "Epoch 15 - Accuracy: 0.549618320610687\n",
      "Epoch 15 - Best Score: 0.5725\n",
      "Epoch 16 - avg_train_loss: 1.8016  avg_val_loss: 2.2609  time: 129s\n",
      "Epoch 16 - Accuracy: 0.5190839694656488\n",
      "Epoch 16 - Best Score: 0.5725\n",
      "Epoch 17 - avg_train_loss: 1.7927  avg_val_loss: 2.2615  time: 129s\n",
      "Epoch 17 - Accuracy: 0.5190839694656488\n",
      "Epoch 17 - Best Score: 0.5725\n",
      "Epoch 18 - avg_train_loss: 1.7874  avg_val_loss: 2.2515  time: 129s\n",
      "Epoch 18 - Accuracy: 0.5343511450381679\n",
      "Epoch 18 - Best Score: 0.5725\n",
      "Epoch 19 - avg_train_loss: 1.7804  avg_val_loss: 2.2556  time: 130s\n",
      "Epoch 19 - Accuracy: 0.549618320610687\n",
      "Epoch 19 - Best Score: 0.5725\n",
      "Epoch 20 - avg_train_loss: 1.7727  avg_val_loss: 2.2589  time: 129s\n",
      "Epoch 20 - Accuracy: 0.5343511450381679\n",
      "Epoch 20 - Best Score: 0.5725\n",
      "Epoch 21 - avg_train_loss: 1.7712  avg_val_loss: 2.2721  time: 129s\n",
      "Epoch 21 - Accuracy: 0.5419847328244275\n",
      "Epoch 21 - Best Score: 0.5725\n",
      "Epoch 22 - avg_train_loss: 1.7662  avg_val_loss: 2.2588  time: 129s\n",
      "Epoch 22 - Accuracy: 0.5343511450381679\n",
      "Epoch 22 - Best Score: 0.5725\n",
      "Epoch 23 - avg_train_loss: 1.7671  avg_val_loss: 2.2614  time: 129s\n",
      "Epoch 23 - Accuracy: 0.5572519083969466\n",
      "Epoch 23 - Best Score: 0.5725\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 24 - avg_train_loss: 1.7566  avg_val_loss: 2.2551  time: 129s\n",
      "Epoch 24 - Accuracy: 0.5343511450381679\n",
      "Epoch 24 - Best Score: 0.5725\n",
      "Epoch 25 - avg_train_loss: 1.7545  avg_val_loss: 2.2422  time: 129s\n",
      "Epoch 25 - Accuracy: 0.5648854961832062\n",
      "Epoch 25 - Best Score: 0.5725\n",
      "Epoch 26 - avg_train_loss: 1.7572  avg_val_loss: 2.2479  time: 129s\n",
      "Epoch 26 - Accuracy: 0.5725190839694656\n",
      "Epoch 26 - Best Score: 0.5725\n",
      "Epoch 27 - avg_train_loss: 1.7537  avg_val_loss: 2.2427  time: 129s\n",
      "Epoch 27 - Accuracy: 0.5648854961832062\n",
      "Epoch 27 - Best Score: 0.5725\n",
      "Epoch 28 - avg_train_loss: 1.7516  avg_val_loss: 2.2484  time: 129s\n",
      "Epoch 28 - Accuracy: 0.5572519083969466\n",
      "Epoch 28 - Best Score: 0.5725\n",
      "Epoch 29 - avg_train_loss: 1.7487  avg_val_loss: 2.2542  time: 129s\n",
      "Epoch 29 - Accuracy: 0.5725190839694656\n",
      "Epoch 29 - Best Score: 0.5725\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.57252\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 2.5470  avg_val_loss: 2.5186  time: 129s\n",
      "Epoch 1 - Accuracy: 0.16793893129770993\n",
      "Epoch 1 - Best Score: 0.1679\n",
      "Epoch 2 - avg_train_loss: 2.4504  avg_val_loss: 2.4583  time: 129s\n",
      "Epoch 2 - Accuracy: 0.2900763358778626\n",
      "Epoch 2 - Best Score: 0.2901\n",
      "Epoch 3 - avg_train_loss: 2.3416  avg_val_loss: 2.3805  time: 129s\n",
      "Epoch 3 - Accuracy: 0.32061068702290074\n",
      "Epoch 3 - Best Score: 0.3206\n",
      "Epoch 4 - avg_train_loss: 2.2540  avg_val_loss: 2.3553  time: 129s\n",
      "Epoch 4 - Accuracy: 0.33587786259541985\n",
      "Epoch 4 - Best Score: 0.3359\n",
      "Epoch 5 - avg_train_loss: 2.1846  avg_val_loss: 2.3432  time: 129s\n",
      "Epoch 5 - Accuracy: 0.3816793893129771\n",
      "Epoch 5 - Best Score: 0.3817\n",
      "Epoch 6 - avg_train_loss: 2.1230  avg_val_loss: 2.3140  time: 129s\n",
      "Epoch 6 - Accuracy: 0.46564885496183206\n",
      "Epoch 6 - Best Score: 0.4656\n",
      "Epoch 7 - avg_train_loss: 2.0661  avg_val_loss: 2.3056  time: 129s\n",
      "Epoch 7 - Accuracy: 0.5114503816793893\n",
      "Epoch 7 - Best Score: 0.5115\n",
      "Epoch 8 - avg_train_loss: 2.0132  avg_val_loss: 2.2860  time: 129s\n",
      "Epoch 8 - Accuracy: 0.5419847328244275\n",
      "Epoch 8 - Best Score: 0.5420\n",
      "Epoch 9 - avg_train_loss: 1.9623  avg_val_loss: 2.2718  time: 129s\n",
      "Epoch 9 - Accuracy: 0.5190839694656488\n",
      "Epoch 9 - Best Score: 0.5420\n",
      "Epoch 10 - avg_train_loss: 1.9180  avg_val_loss: 2.2619  time: 129s\n",
      "Epoch 10 - Accuracy: 0.5419847328244275\n",
      "Epoch 10 - Best Score: 0.5420\n",
      "Epoch 11 - avg_train_loss: 1.8816  avg_val_loss: 2.2599  time: 129s\n",
      "Epoch 11 - Accuracy: 0.5114503816793893\n",
      "Epoch 11 - Best Score: 0.5420\n",
      "Epoch 12 - avg_train_loss: 1.8500  avg_val_loss: 2.2600  time: 129s\n",
      "Epoch 12 - Accuracy: 0.5419847328244275\n",
      "Epoch 12 - Best Score: 0.5420\n",
      "Epoch 13 - avg_train_loss: 1.8403  avg_val_loss: 2.2491  time: 129s\n",
      "Epoch 13 - Accuracy: 0.5648854961832062\n",
      "Epoch 13 - Best Score: 0.5649\n",
      "Epoch 14 - avg_train_loss: 1.8243  avg_val_loss: 2.2467  time: 130s\n",
      "Epoch 14 - Accuracy: 0.549618320610687\n",
      "Epoch 14 - Best Score: 0.5649\n",
      "Epoch 15 - avg_train_loss: 1.8081  avg_val_loss: 2.2460  time: 129s\n",
      "Epoch 15 - Accuracy: 0.5725190839694656\n",
      "Epoch 15 - Best Score: 0.5725\n",
      "Epoch 16 - avg_train_loss: 1.8007  avg_val_loss: 2.2355  time: 129s\n",
      "Epoch 16 - Accuracy: 0.6030534351145038\n",
      "Epoch 16 - Best Score: 0.6031\n",
      "Epoch 17 - avg_train_loss: 1.7915  avg_val_loss: 2.2278  time: 129s\n",
      "Epoch 17 - Accuracy: 0.6183206106870229\n",
      "Epoch 17 - Best Score: 0.6183\n",
      "Epoch 18 - avg_train_loss: 1.7895  avg_val_loss: 2.2497  time: 129s\n",
      "Epoch 18 - Accuracy: 0.549618320610687\n",
      "Epoch 18 - Best Score: 0.6183\n",
      "Epoch 19 - avg_train_loss: 1.7792  avg_val_loss: 2.2420  time: 129s\n",
      "Epoch 19 - Accuracy: 0.5419847328244275\n",
      "Epoch 19 - Best Score: 0.6183\n",
      "Epoch 20 - avg_train_loss: 1.7815  avg_val_loss: 2.2416  time: 129s\n",
      "Epoch 20 - Accuracy: 0.5419847328244275\n",
      "Epoch 20 - Best Score: 0.6183\n",
      "Epoch 21 - avg_train_loss: 1.7735  avg_val_loss: 2.2492  time: 129s\n",
      "Epoch 21 - Accuracy: 0.549618320610687\n",
      "Epoch 21 - Best Score: 0.6183\n",
      "Epoch 22 - avg_train_loss: 1.7657  avg_val_loss: 2.2406  time: 129s\n",
      "Epoch 22 - Accuracy: 0.5419847328244275\n",
      "Epoch 22 - Best Score: 0.6183\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 23 - avg_train_loss: 1.7617  avg_val_loss: 2.2464  time: 129s\n",
      "Epoch 23 - Accuracy: 0.5572519083969466\n",
      "Epoch 23 - Best Score: 0.6183\n",
      "Epoch 24 - avg_train_loss: 1.7576  avg_val_loss: 2.2259  time: 129s\n",
      "Epoch 24 - Accuracy: 0.5801526717557252\n",
      "Epoch 24 - Best Score: 0.6183\n",
      "Epoch 25 - avg_train_loss: 1.7566  avg_val_loss: 2.2212  time: 129s\n",
      "Epoch 25 - Accuracy: 0.5801526717557252\n",
      "Epoch 25 - Best Score: 0.6183\n",
      "Epoch 26 - avg_train_loss: 1.7606  avg_val_loss: 2.2282  time: 129s\n",
      "Epoch 26 - Accuracy: 0.5801526717557252\n",
      "Epoch 26 - Best Score: 0.6183\n",
      "Epoch 27 - avg_train_loss: 1.7560  avg_val_loss: 2.2140  time: 129s\n",
      "Epoch 27 - Accuracy: 0.6030534351145038\n",
      "Epoch 27 - Best Score: 0.6183\n",
      "Epoch 28 - avg_train_loss: 1.7578  avg_val_loss: 2.2334  time: 130s\n",
      "Epoch 28 - Accuracy: 0.5877862595419847\n",
      "Epoch 28 - Best Score: 0.6183\n",
      "Epoch 29 - avg_train_loss: 1.7550  avg_val_loss: 2.2285  time: 129s\n",
      "Epoch 29 - Accuracy: 0.5801526717557252\n",
      "Epoch 29 - Best Score: 0.6183\n",
      "Epoch 30 - avg_train_loss: 1.7477  avg_val_loss: 2.2179  time: 130s\n",
      "Epoch 30 - Accuracy: 0.5877862595419847\n",
      "Epoch 30 - Best Score: 0.6183\n",
      "Epoch 31 - avg_train_loss: 1.7493  avg_val_loss: 2.2399  time: 130s\n",
      "Epoch 31 - Accuracy: 0.5877862595419847\n",
      "Epoch 31 - Best Score: 0.6183\n",
      "Epoch 32 - avg_train_loss: 1.7543  avg_val_loss: 2.2477  time: 129s\n",
      "Epoch 32 - Accuracy: 0.5725190839694656\n",
      "Epoch 32 - Best Score: 0.6183\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 33 - avg_train_loss: 1.7543  avg_val_loss: 2.2247  time: 129s\n",
      "Epoch 33 - Accuracy: 0.5877862595419847\n",
      "Epoch 33 - Best Score: 0.6183\n",
      "Epoch 34 - avg_train_loss: 1.7510  avg_val_loss: 2.2346  time: 129s\n",
      "Epoch 34 - Accuracy: 0.6030534351145038\n",
      "Epoch 34 - Best Score: 0.6183\n",
      "Epoch 35 - avg_train_loss: 1.7551  avg_val_loss: 2.2237  time: 130s\n",
      "Epoch 35 - Accuracy: 0.5954198473282443\n",
      "Epoch 35 - Best Score: 0.6183\n",
      "Epoch 36 - avg_train_loss: 1.7488  avg_val_loss: 2.2388  time: 129s\n",
      "Epoch 36 - Accuracy: 0.5801526717557252\n",
      "Epoch 36 - Best Score: 0.6183\n",
      "Epoch 37 - avg_train_loss: 1.7507  avg_val_loss: 2.2284  time: 129s\n",
      "Epoch 37 - Accuracy: 0.5801526717557252\n",
      "Epoch 37 - Best Score: 0.6183\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.61832\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 2.5461  avg_val_loss: 2.5256  time: 129s\n",
      "Epoch 1 - Accuracy: 0.09923664122137404\n",
      "Epoch 1 - Best Score: 0.0992\n",
      "Epoch 2 - avg_train_loss: 2.4431  avg_val_loss: 2.4772  time: 129s\n",
      "Epoch 2 - Accuracy: 0.22900763358778625\n",
      "Epoch 2 - Best Score: 0.2290\n",
      "Epoch 3 - avg_train_loss: 2.3538  avg_val_loss: 2.4145  time: 129s\n",
      "Epoch 3 - Accuracy: 0.3282442748091603\n",
      "Epoch 3 - Best Score: 0.3282\n",
      "Epoch 4 - avg_train_loss: 2.2709  avg_val_loss: 2.3779  time: 129s\n",
      "Epoch 4 - Accuracy: 0.4122137404580153\n",
      "Epoch 4 - Best Score: 0.4122\n",
      "Epoch 5 - avg_train_loss: 2.1843  avg_val_loss: 2.3313  time: 129s\n",
      "Epoch 5 - Accuracy: 0.48854961832061067\n",
      "Epoch 5 - Best Score: 0.4885\n",
      "Epoch 6 - avg_train_loss: 2.0942  avg_val_loss: 2.2922  time: 130s\n",
      "Epoch 6 - Accuracy: 0.5343511450381679\n",
      "Epoch 6 - Best Score: 0.5344\n",
      "Epoch 7 - avg_train_loss: 2.0304  avg_val_loss: 2.2687  time: 130s\n",
      "Epoch 7 - Accuracy: 0.5343511450381679\n",
      "Epoch 7 - Best Score: 0.5344\n",
      "Epoch 8 - avg_train_loss: 1.9761  avg_val_loss: 2.2676  time: 130s\n",
      "Epoch 8 - Accuracy: 0.5267175572519084\n",
      "Epoch 8 - Best Score: 0.5344\n",
      "Epoch 9 - avg_train_loss: 1.9442  avg_val_loss: 2.2476  time: 129s\n",
      "Epoch 9 - Accuracy: 0.5648854961832062\n",
      "Epoch 9 - Best Score: 0.5649\n",
      "Epoch 10 - avg_train_loss: 1.8997  avg_val_loss: 2.2554  time: 130s\n",
      "Epoch 10 - Accuracy: 0.5572519083969466\n",
      "Epoch 10 - Best Score: 0.5649\n",
      "Epoch 11 - avg_train_loss: 1.8797  avg_val_loss: 2.2304  time: 130s\n",
      "Epoch 11 - Accuracy: 0.6106870229007634\n",
      "Epoch 11 - Best Score: 0.6107\n",
      "Epoch 12 - avg_train_loss: 1.8518  avg_val_loss: 2.2306  time: 129s\n",
      "Epoch 12 - Accuracy: 0.6106870229007634\n",
      "Epoch 12 - Best Score: 0.6107\n",
      "Epoch 13 - avg_train_loss: 1.8405  avg_val_loss: 2.2242  time: 129s\n",
      "Epoch 13 - Accuracy: 0.648854961832061\n",
      "Epoch 13 - Best Score: 0.6489\n",
      "Epoch 14 - avg_train_loss: 1.8209  avg_val_loss: 2.2110  time: 130s\n",
      "Epoch 14 - Accuracy: 0.6183206106870229\n",
      "Epoch 14 - Best Score: 0.6489\n",
      "Epoch 15 - avg_train_loss: 1.8124  avg_val_loss: 2.2114  time: 130s\n",
      "Epoch 15 - Accuracy: 0.6106870229007634\n",
      "Epoch 15 - Best Score: 0.6489\n",
      "Epoch 16 - avg_train_loss: 1.8047  avg_val_loss: 2.2085  time: 129s\n",
      "Epoch 16 - Accuracy: 0.6335877862595419\n",
      "Epoch 16 - Best Score: 0.6489\n",
      "Epoch 17 - avg_train_loss: 1.7948  avg_val_loss: 2.2238  time: 129s\n",
      "Epoch 17 - Accuracy: 0.5801526717557252\n",
      "Epoch 17 - Best Score: 0.6489\n",
      "Epoch 18 - avg_train_loss: 1.7879  avg_val_loss: 2.2147  time: 129s\n",
      "Epoch 18 - Accuracy: 0.6106870229007634\n",
      "Epoch 18 - Best Score: 0.6489\n",
      "Epoch 19 - avg_train_loss: 1.7852  avg_val_loss: 2.2136  time: 129s\n",
      "Epoch 19 - Accuracy: 0.6183206106870229\n",
      "Epoch 19 - Best Score: 0.6489\n",
      "Epoch 20 - avg_train_loss: 1.7731  avg_val_loss: 2.2183  time: 130s\n",
      "Epoch 20 - Accuracy: 0.6106870229007634\n",
      "Epoch 20 - Best Score: 0.6489\n",
      "Epoch 21 - avg_train_loss: 1.7717  avg_val_loss: 2.1871  time: 129s\n",
      "Epoch 21 - Accuracy: 0.6412213740458015\n",
      "Epoch 21 - Best Score: 0.6489\n",
      "Epoch 22 - avg_train_loss: 1.7647  avg_val_loss: 2.2004  time: 130s\n",
      "Epoch 22 - Accuracy: 0.6259541984732825\n",
      "Epoch 22 - Best Score: 0.6489\n",
      "Epoch 23 - avg_train_loss: 1.7706  avg_val_loss: 2.2067  time: 130s\n",
      "Epoch 23 - Accuracy: 0.6106870229007634\n",
      "Epoch 23 - Best Score: 0.6489\n",
      "Epoch 24 - avg_train_loss: 1.7540  avg_val_loss: 2.1949  time: 129s\n",
      "Epoch 24 - Accuracy: 0.6641221374045801\n",
      "Epoch 24 - Best Score: 0.6641\n",
      "Epoch 25 - avg_train_loss: 1.7569  avg_val_loss: 2.1962  time: 130s\n",
      "Epoch 25 - Accuracy: 0.6412213740458015\n",
      "Epoch 25 - Best Score: 0.6641\n",
      "Epoch 26 - avg_train_loss: 1.7573  avg_val_loss: 2.2048  time: 130s\n",
      "Epoch 26 - Accuracy: 0.5954198473282443\n",
      "Epoch 26 - Best Score: 0.6641\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 27 - avg_train_loss: 1.7558  avg_val_loss: 2.2078  time: 129s\n",
      "Epoch 27 - Accuracy: 0.5877862595419847\n",
      "Epoch 27 - Best Score: 0.6641\n",
      "Epoch 28 - avg_train_loss: 1.7490  avg_val_loss: 2.2056  time: 130s\n",
      "Epoch 28 - Accuracy: 0.6106870229007634\n",
      "Epoch 28 - Best Score: 0.6641\n",
      "Epoch 29 - avg_train_loss: 1.7484  avg_val_loss: 2.2168  time: 129s\n",
      "Epoch 29 - Accuracy: 0.6259541984732825\n",
      "Epoch 29 - Best Score: 0.6641\n",
      "Epoch 30 - avg_train_loss: 1.7468  avg_val_loss: 2.2064  time: 130s\n",
      "Epoch 30 - Accuracy: 0.5954198473282443\n",
      "Epoch 30 - Best Score: 0.6641\n",
      "Epoch 31 - avg_train_loss: 1.7467  avg_val_loss: 2.2063  time: 130s\n",
      "Epoch 31 - Accuracy: 0.6183206106870229\n",
      "Epoch 31 - Best Score: 0.6641\n",
      "Epoch 32 - avg_train_loss: 1.7477  avg_val_loss: 2.2169  time: 129s\n",
      "Epoch 32 - Accuracy: 0.5725190839694656\n",
      "Epoch 32 - Best Score: 0.6641\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 33 - avg_train_loss: 1.7443  avg_val_loss: 2.2140  time: 129s\n",
      "Epoch 33 - Accuracy: 0.6183206106870229\n",
      "Epoch 33 - Best Score: 0.6641\n",
      "Epoch 34 - avg_train_loss: 1.7418  avg_val_loss: 2.1982  time: 129s\n",
      "Epoch 34 - Accuracy: 0.6259541984732825\n",
      "Epoch 34 - Best Score: 0.6641\n",
      "Epoch 35 - avg_train_loss: 1.7402  avg_val_loss: 2.2133  time: 130s\n",
      "Epoch 35 - Accuracy: 0.6106870229007634\n",
      "Epoch 35 - Best Score: 0.6641\n",
      "Epoch 36 - avg_train_loss: 1.7441  avg_val_loss: 2.1980  time: 129s\n",
      "Epoch 36 - Accuracy: 0.6183206106870229\n",
      "Epoch 36 - Best Score: 0.6641\n",
      "Epoch 37 - avg_train_loss: 1.7450  avg_val_loss: 2.2044  time: 130s\n",
      "Epoch 37 - Accuracy: 0.6412213740458015\n",
      "Epoch 37 - Best Score: 0.6641\n",
      "Epoch 38 - avg_train_loss: 1.7392  avg_val_loss: 2.2006  time: 130s\n",
      "Epoch 38 - Accuracy: 0.6412213740458015\n",
      "Epoch 38 - Best Score: 0.6641\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 39 - avg_train_loss: 1.7443  avg_val_loss: 2.2130  time: 130s\n",
      "Epoch 39 - Accuracy: 0.6183206106870229\n",
      "Epoch 39 - Best Score: 0.6641\n",
      "Epoch 40 - avg_train_loss: 1.7454  avg_val_loss: 2.1991  time: 130s\n",
      "Epoch 40 - Accuracy: 0.6183206106870229\n",
      "Epoch 40 - Best Score: 0.6641\n",
      "Epoch 41 - avg_train_loss: 1.7443  avg_val_loss: 2.1964  time: 129s\n",
      "Epoch 41 - Accuracy: 0.6183206106870229\n",
      "Epoch 41 - Best Score: 0.6641\n",
      "Epoch 42 - avg_train_loss: 1.7440  avg_val_loss: 2.2014  time: 129s\n",
      "Epoch 42 - Accuracy: 0.6106870229007634\n",
      "Epoch 42 - Best Score: 0.6641\n",
      "Epoch 43 - avg_train_loss: 1.7432  avg_val_loss: 2.2089  time: 130s\n",
      "Epoch 43 - Accuracy: 0.6106870229007634\n",
      "Epoch 43 - Best Score: 0.6641\n",
      "Epoch 44 - avg_train_loss: 1.7460  avg_val_loss: 2.1990  time: 129s\n",
      "Epoch 44 - Accuracy: 0.6183206106870229\n",
      "Epoch 44 - Best Score: 0.6641\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.66412\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 2.5474  avg_val_loss: 2.5240  time: 129s\n",
      "Epoch 1 - Accuracy: 0.12307692307692308\n",
      "Epoch 1 - Best Score: 0.1231\n",
      "Epoch 2 - avg_train_loss: 2.4566  avg_val_loss: 2.4373  time: 129s\n",
      "Epoch 2 - Accuracy: 0.24615384615384617\n",
      "Epoch 2 - Best Score: 0.2462\n",
      "Epoch 3 - avg_train_loss: 2.3400  avg_val_loss: 2.3748  time: 129s\n",
      "Epoch 3 - Accuracy: 0.34615384615384615\n",
      "Epoch 3 - Best Score: 0.3462\n",
      "Epoch 4 - avg_train_loss: 2.2396  avg_val_loss: 2.3448  time: 129s\n",
      "Epoch 4 - Accuracy: 0.4076923076923077\n",
      "Epoch 4 - Best Score: 0.4077\n",
      "Epoch 5 - avg_train_loss: 2.1564  avg_val_loss: 2.3315  time: 129s\n",
      "Epoch 5 - Accuracy: 0.4230769230769231\n",
      "Epoch 5 - Best Score: 0.4231\n",
      "Epoch 6 - avg_train_loss: 2.0831  avg_val_loss: 2.3216  time: 129s\n",
      "Epoch 6 - Accuracy: 0.47692307692307695\n",
      "Epoch 6 - Best Score: 0.4769\n",
      "Epoch 7 - avg_train_loss: 2.0197  avg_val_loss: 2.2959  time: 129s\n",
      "Epoch 7 - Accuracy: 0.5076923076923077\n",
      "Epoch 7 - Best Score: 0.5077\n",
      "Epoch 8 - avg_train_loss: 1.9619  avg_val_loss: 2.2816  time: 129s\n",
      "Epoch 8 - Accuracy: 0.5153846153846153\n",
      "Epoch 8 - Best Score: 0.5154\n",
      "Epoch 9 - avg_train_loss: 1.9179  avg_val_loss: 2.2646  time: 130s\n",
      "Epoch 9 - Accuracy: 0.5\n",
      "Epoch 9 - Best Score: 0.5154\n",
      "Epoch 10 - avg_train_loss: 1.8901  avg_val_loss: 2.2492  time: 129s\n",
      "Epoch 10 - Accuracy: 0.5307692307692308\n",
      "Epoch 10 - Best Score: 0.5308\n",
      "Epoch 11 - avg_train_loss: 1.8697  avg_val_loss: 2.2621  time: 129s\n",
      "Epoch 11 - Accuracy: 0.5230769230769231\n",
      "Epoch 11 - Best Score: 0.5308\n",
      "Epoch 12 - avg_train_loss: 1.8520  avg_val_loss: 2.2533  time: 129s\n",
      "Epoch 12 - Accuracy: 0.5384615384615384\n",
      "Epoch 12 - Best Score: 0.5385\n",
      "Epoch 13 - avg_train_loss: 1.8320  avg_val_loss: 2.2577  time: 129s\n",
      "Epoch 13 - Accuracy: 0.5461538461538461\n",
      "Epoch 13 - Best Score: 0.5462\n",
      "Epoch 14 - avg_train_loss: 1.8239  avg_val_loss: 2.2419  time: 129s\n",
      "Epoch 14 - Accuracy: 0.5615384615384615\n",
      "Epoch 14 - Best Score: 0.5615\n",
      "Epoch 15 - avg_train_loss: 1.8127  avg_val_loss: 2.2348  time: 129s\n",
      "Epoch 15 - Accuracy: 0.5615384615384615\n",
      "Epoch 15 - Best Score: 0.5615\n",
      "Epoch 16 - avg_train_loss: 1.8051  avg_val_loss: 2.2408  time: 129s\n",
      "Epoch 16 - Accuracy: 0.5384615384615384\n",
      "Epoch 16 - Best Score: 0.5615\n",
      "Epoch 17 - avg_train_loss: 1.8011  avg_val_loss: 2.2279  time: 129s\n",
      "Epoch 17 - Accuracy: 0.5538461538461539\n",
      "Epoch 17 - Best Score: 0.5615\n",
      "Epoch 18 - avg_train_loss: 1.7847  avg_val_loss: 2.2437  time: 129s\n",
      "Epoch 18 - Accuracy: 0.5461538461538461\n",
      "Epoch 18 - Best Score: 0.5615\n",
      "Epoch 19 - avg_train_loss: 1.7776  avg_val_loss: 2.2359  time: 129s\n",
      "Epoch 19 - Accuracy: 0.5615384615384615\n",
      "Epoch 19 - Best Score: 0.5615\n",
      "Epoch 20 - avg_train_loss: 1.7709  avg_val_loss: 2.2271  time: 129s\n",
      "Epoch 20 - Accuracy: 0.5461538461538461\n",
      "Epoch 20 - Best Score: 0.5615\n",
      "Epoch 21 - avg_train_loss: 1.7682  avg_val_loss: 2.2297  time: 129s\n",
      "Epoch 21 - Accuracy: 0.5461538461538461\n",
      "Epoch 21 - Best Score: 0.5615\n",
      "Epoch 22 - avg_train_loss: 1.7669  avg_val_loss: 2.2283  time: 129s\n",
      "Epoch 22 - Accuracy: 0.5692307692307692\n",
      "Epoch 22 - Best Score: 0.5692\n",
      "Epoch 23 - avg_train_loss: 1.7617  avg_val_loss: 2.2214  time: 129s\n",
      "Epoch 23 - Accuracy: 0.5692307692307692\n",
      "Epoch 23 - Best Score: 0.5692\n",
      "Epoch 24 - avg_train_loss: 1.7595  avg_val_loss: 2.2195  time: 129s\n",
      "Epoch 24 - Accuracy: 0.5615384615384615\n",
      "Epoch 24 - Best Score: 0.5692\n",
      "Epoch 25 - avg_train_loss: 1.7577  avg_val_loss: 2.2253  time: 129s\n",
      "Epoch 25 - Accuracy: 0.5461538461538461\n",
      "Epoch 25 - Best Score: 0.5692\n",
      "Epoch 26 - avg_train_loss: 1.7575  avg_val_loss: 2.2317  time: 129s\n",
      "Epoch 26 - Accuracy: 0.5615384615384615\n",
      "Epoch 26 - Best Score: 0.5692\n",
      "Epoch 27 - avg_train_loss: 1.7515  avg_val_loss: 2.2576  time: 129s\n",
      "Epoch 27 - Accuracy: 0.5230769230769231\n",
      "Epoch 27 - Best Score: 0.5692\n",
      "Epoch 28 - avg_train_loss: 1.7487  avg_val_loss: 2.2165  time: 129s\n",
      "Epoch 28 - Accuracy: 0.5615384615384615\n",
      "Epoch 28 - Best Score: 0.5692\n",
      "Epoch 29 - avg_train_loss: 1.7486  avg_val_loss: 2.2323  time: 129s\n",
      "Epoch 29 - Accuracy: 0.5384615384615384\n",
      "Epoch 29 - Best Score: 0.5692\n",
      "Epoch 30 - avg_train_loss: 1.7482  avg_val_loss: 2.2261  time: 129s\n",
      "Epoch 30 - Accuracy: 0.5461538461538461\n",
      "Epoch 30 - Best Score: 0.5692\n",
      "Epoch 31 - avg_train_loss: 1.7394  avg_val_loss: 2.2355  time: 129s\n",
      "Epoch 31 - Accuracy: 0.5307692307692308\n",
      "Epoch 31 - Best Score: 0.5692\n",
      "Epoch 32 - avg_train_loss: 1.7422  avg_val_loss: 2.2264  time: 129s\n",
      "Epoch 32 - Accuracy: 0.5846153846153846\n",
      "Epoch 32 - Best Score: 0.5846\n",
      "Epoch 33 - avg_train_loss: 1.7389  avg_val_loss: 2.2416  time: 129s\n",
      "Epoch 33 - Accuracy: 0.5384615384615384\n",
      "Epoch 33 - Best Score: 0.5846\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 34 - avg_train_loss: 1.7420  avg_val_loss: 2.2281  time: 129s\n",
      "Epoch 34 - Accuracy: 0.5461538461538461\n",
      "Epoch 34 - Best Score: 0.5846\n",
      "Epoch 35 - avg_train_loss: 1.7362  avg_val_loss: 2.2325  time: 129s\n",
      "Epoch 35 - Accuracy: 0.5538461538461539\n",
      "Epoch 35 - Best Score: 0.5846\n",
      "Epoch 36 - avg_train_loss: 1.7321  avg_val_loss: 2.2215  time: 129s\n",
      "Epoch 36 - Accuracy: 0.5307692307692308\n",
      "Epoch 36 - Best Score: 0.5846\n",
      "Epoch 37 - avg_train_loss: 1.7336  avg_val_loss: 2.2456  time: 129s\n",
      "Epoch 37 - Accuracy: 0.5384615384615384\n",
      "Epoch 37 - Best Score: 0.5846\n",
      "Epoch 38 - avg_train_loss: 1.7372  avg_val_loss: 2.2178  time: 129s\n",
      "Epoch 38 - Accuracy: 0.5538461538461539\n",
      "Epoch 38 - Best Score: 0.5846\n",
      "Epoch 39 - avg_train_loss: 1.7395  avg_val_loss: 2.2244  time: 129s\n",
      "Epoch 39 - Accuracy: 0.5384615384615384\n",
      "Epoch 39 - Best Score: 0.5846\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 40 - avg_train_loss: 1.7307  avg_val_loss: 2.2300  time: 129s\n",
      "Epoch 40 - Accuracy: 0.5307692307692308\n",
      "Epoch 40 - Best Score: 0.5846\n",
      "Epoch 41 - avg_train_loss: 1.7372  avg_val_loss: 2.2353  time: 129s\n",
      "Epoch 41 - Accuracy: 0.5615384615384615\n",
      "Epoch 41 - Best Score: 0.5846\n",
      "Epoch 42 - avg_train_loss: 1.7331  avg_val_loss: 2.2139  time: 129s\n",
      "Epoch 42 - Accuracy: 0.5692307692307692\n",
      "Epoch 42 - Best Score: 0.5846\n",
      "Epoch 43 - avg_train_loss: 1.7358  avg_val_loss: 2.2196  time: 129s\n",
      "Epoch 43 - Accuracy: 0.5384615384615384\n",
      "Epoch 43 - Best Score: 0.5846\n",
      "Epoch 44 - avg_train_loss: 1.7360  avg_val_loss: 2.2341  time: 129s\n",
      "Epoch 44 - Accuracy: 0.5615384615384615\n",
      "Epoch 44 - Best Score: 0.5846\n",
      "Epoch 45 - avg_train_loss: 1.7339  avg_val_loss: 2.2303  time: 129s\n",
      "Epoch 45 - Accuracy: 0.5615384615384615\n",
      "Epoch 45 - Best Score: 0.5846\n",
      "Epoch 46 - avg_train_loss: 1.7330  avg_val_loss: 2.2232  time: 129s\n",
      "Epoch 46 - Accuracy: 0.5615384615384615\n",
      "Epoch 46 - Best Score: 0.5846\n",
      "Epoch 47 - avg_train_loss: 1.7329  avg_val_loss: 2.2227  time: 129s\n",
      "Epoch 47 - Accuracy: 0.5461538461538461\n",
      "Epoch 47 - Best Score: 0.5846\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 48 - avg_train_loss: 1.7297  avg_val_loss: 2.2217  time: 129s\n",
      "Epoch 48 - Accuracy: 0.5538461538461539\n",
      "Epoch 48 - Best Score: 0.5846\n",
      "Epoch 49 - avg_train_loss: 1.7360  avg_val_loss: 2.2232  time: 129s\n",
      "Epoch 49 - Accuracy: 0.5615384615384615\n",
      "Epoch 49 - Best Score: 0.5846\n",
      "Epoch 50 - avg_train_loss: 1.7331  avg_val_loss: 2.2235  time: 129s\n",
      "Epoch 50 - Accuracy: 0.5769230769230769\n",
      "Epoch 50 - Best Score: 0.5846\n",
      "Epoch 51 - avg_train_loss: 1.7348  avg_val_loss: 2.2247  time: 129s\n",
      "Epoch 51 - Accuracy: 0.5538461538461539\n",
      "Epoch 51 - Best Score: 0.5846\n",
      "Epoch 52 - avg_train_loss: 1.7345  avg_val_loss: 2.2238  time: 129s\n",
      "Epoch 52 - Accuracy: 0.5384615384615384\n",
      "Epoch 52 - Best Score: 0.5846\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.58462\n",
      "========== CV ==========\n",
      "Score: 0.60550\n",
      "CPU times: user 22h 55min 57s, sys: 2h 48s, total: 1d 56min 46s\n",
      "Wall time: 7h 52min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  fold  preds\n",
       "0         5     0      5\n",
       "1         6     0      6\n",
       "2         4     0      4\n",
       "3         7     0      7\n",
       "4         0     0      0\n",
       "..      ...   ...    ...\n",
       "125       3     4      3\n",
       "126      11     4     11\n",
       "127       5     4      2\n",
       "128       9     4      9\n",
       "129       2     4      2\n",
       "\n",
       "[654 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "# print(\"========== CV ==========\")\n",
    "# TrainRunner(model_config)._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"], verbose=True)\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train_labels, label=\"true\")\n",
    "plt.show()\n",
    "sns.countplot(x=Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "   id   y\n",
      "0   0   2\n",
      "1   1   3\n",
      "2   2  10\n",
      "3   3   2\n",
      "4   4   1\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "InferenceRunner(model_config).run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac819026-9e1b-4dd7-b02d-c0cecfeff158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
