{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c359c42d-0550-4236-9b24-1ba0a9ac7e73",
   "metadata": {},
   "source": [
    "- base version: exp008\n",
    "- add: resnest50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90eab5f1-927b-4820-b258-ea8f791a4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17908034-de36-4913-8e43-b3b8a21932b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputPath:\n",
    "    _prefix: str = \"../input\"\n",
    "    train_images: str = f\"{_prefix}/christ-train-imgs.npz\"\n",
    "    train_labels: str = f\"{_prefix}/christ-train-labels.npz\"\n",
    "    test_images: str = f\"{_prefix}/christ-test-imgs.npz\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class OutputPath:\n",
    "    _prefix: str = \"../output\"\n",
    "    model: str = f\"{_prefix}/model\"\n",
    "    submission: str = f\"{_prefix}/submission\"\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Basic:\n",
    "    run_name: str = \"exp010\"\n",
    "    is_debug: bool = False\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Kfold:\n",
    "    number: int = 5\n",
    "    method: str = \"skf\"\n",
    "    shuffle: bool = True\n",
    "    columns: List[str] = field(default_factory=lambda: [\"target\"])\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Adam:\n",
    "    name: str = \"Adam\"\n",
    "    lr: float = 1e-5\n",
    "    weight_decay: float = 0\n",
    "    amsgrad: bool = False\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class ReduceLROnPlateau:\n",
    "    name: str = \"ReduceLROnPlateau\"\n",
    "    mode: str = \"min\"\n",
    "    factor: float = 0.1\n",
    "    patience: int = 5\n",
    "    verbose: bool = True\n",
    "    eps: float = 1e-8\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Params:\n",
    "    model_name: str = \"resnest50d\"\n",
    "    batch_size: int = 16\n",
    "    test_batch_size: int = 128\n",
    "    epochs: int = 3 if Basic.is_debug else 100\n",
    "    image_size: int = 384\n",
    "    num_workers: int = 0\n",
    "    target_size: int = 13\n",
    "    # Union[Adam]\n",
    "    optimizer: Adam = Adam()\n",
    "    # Union[CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau]\n",
    "    scheduler: ReduceLROnPlateau = ReduceLROnPlateau()\n",
    "    pretrained: bool = True\n",
    "    num_aug: int = 5\n",
    "    num_tta: int = 5\n",
    "    early_stopping_rounds: int = 20\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    basic: Basic = Basic()\n",
    "    kfold: Kfold = Kfold()\n",
    "    params: Params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fec5d5-f634-46bc-9cb6-437c0f3b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in os.listdir(OutputPath.model):\n",
    "#     if x.startswith(f\"{Basic.run_name}_\"):\n",
    "#         os.remove(f\"{OutputPath.model}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e688a697-6d8e-40a5-89a3-56833b01cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_sessions = [x.split(\"_\")[0] for x in os.listdir(OutputPath.model) if x.endswith(\"_0.pth\")]\n",
    "assert Basic.run_name not in past_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b0b95d9-6d21-48a4-8ef9-d085e183e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Jbl:\n",
    "    @staticmethod\n",
    "    def load(filepath: str) -> Any:\n",
    "        return joblib.load(filepath)\n",
    "\n",
    "    @staticmethod\n",
    "    def save(obj_: Any, filepath: str) -> None:\n",
    "        joblib.dump(obj_, filepath, compress=3)\n",
    "\n",
    "\n",
    "def fix_seed(seed: int = 42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "def time_since(since: time.time, percent: float) -> str:\n",
    "    def as_minutes(s):\n",
    "        m = math.floor(s / 60)\n",
    "        s -= m * 60\n",
    "        return \"%dm %ds\" % (m, s)\n",
    "\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cc936d-6003-4e02-ba1f-d42cf039cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_npz(path: str) -> np.array:\n",
    "    x = np.load(path)[\"arr_0\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169f341c-c861-4c5d-918c-201017c494da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_kf(cfg: ModelConfig) -> Generator:\n",
    "    if cfg.kfold.method == \"kf\":\n",
    "        kf = KFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"skf\":\n",
    "        kf = StratifiedKFold(\n",
    "            n_splits=cfg.kfold.number,\n",
    "            shuffle=cfg.kfold.shuffle,\n",
    "            random_state=cfg.basic.seed,\n",
    "        )\n",
    "    elif cfg.kfold.method == \"gkf\":\n",
    "        kf = GroupKFold(n_splits=cfg.kfold.number)\n",
    "    elif cfg.kfold.method == \"sgkf\":\n",
    "        kf = StratifiedGroupKFold(\n",
    "            n_splits=cfg.kfold.number, random_state=cfg.basic.seed\n",
    "        )\n",
    "    elif cfg.kfold.method == \"tskf\":\n",
    "        kf = TimeSeriesSplit(n_splits=cfg.kfold.number)\n",
    "    else:\n",
    "        raise ValueError(f\"{cfg.kfold.method} is not supported\")\n",
    "    return kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1e049a-17be-4901-a59d-8d475c180753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "class ProbSpaceDataset(data.Dataset):\n",
    "    def __init__(self, images: np.array, labels: Optional[np.array] = None, is_train: bool = True) -> None:\n",
    "        \"\"\"images.shape: (b, h, w, c), labels: (b,)\"\"\"\n",
    "        assert (is_train and labels is not None) or (not is_train and labels is None)        \n",
    "        self.is_train = is_train\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "        size = (ModelConfig.params.image_size, ModelConfig.params.image_size)\n",
    "        additional_items = (\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                T.Resize(size),\n",
    "            ]\n",
    "            if not is_train\n",
    "            else [\n",
    "                T.ToPILImage(),\n",
    "                T.RandomGrayscale(p=0.2),\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.ColorJitter(\n",
    "                    brightness=0.3,\n",
    "                    contrast=0.5,\n",
    "                    saturation=[0.8, 1.3],\n",
    "                    hue=[-0.05, 0.05],\n",
    "                ),\n",
    "                T.RandomResizedCrop(size),\n",
    "            ]\n",
    "        )\n",
    "        self.transformer = T.Compose(\n",
    "            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index) -> Dict[str, Any]:\n",
    "        image = self.images[index]\n",
    "        image = self.transformer(image)\n",
    "        if self.is_train:\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            label = -1\n",
    "        return {\"image\": image, \"label\": label}\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d403d8d-cd02-4fca-9c31-a32cdfbc7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ProbSpaceModel(nn.Module):\n",
    "    def __init__(self, model_config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_config.params.model_name, \n",
    "            pretrained=model_config.params.pretrained, \n",
    "            num_classes=model_config.params.target_size,\n",
    "        )\n",
    "#         self.in_features = self.backbone.fc.in_features\n",
    "#         self.backbone.fc = nn.Linear(self.in_features, model_config.params.target_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_model(model_config: ModelConfig):\n",
    "    model = ProbSpaceModel(model_config)\n",
    "    model.to(model_config.basic.device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb29cd98-7770-4f3e-813f-461679503034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from collections import Counter, OrderedDict\n",
    "from logging import Logger\n",
    "from typing import Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BaseRunner:\n",
    "    def __init__(self, cfg: ModelConfig):\n",
    "        self.cfg = cfg\n",
    "        self.params = cfg.params\n",
    "\n",
    "    def _get_scheduler(\n",
    "        self, optimizer: Union[optim.Adam]\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if self.params.scheduler.name == \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.params.scheduler.mode,\n",
    "                factor=self.params.scheduler.factor,\n",
    "                patience=self.params.scheduler.patience,\n",
    "                verbose=self.params.scheduler.verbose,\n",
    "                eps=self.params.scheduler.eps,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.scheduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _step_scheduler(\n",
    "        self,\n",
    "        scheduler: Union[\n",
    "            lr_scheduler.ReduceLROnPlateau,\n",
    "        ],\n",
    "        avg_val_loss,\n",
    "    ) -> Union[\n",
    "        lr_scheduler.ReduceLROnPlateau,\n",
    "    ]:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else:\n",
    "            raise ValueError(f\"{self.params.shceduler.name} is not supported\")\n",
    "        return scheduler\n",
    "\n",
    "    def _evaluate(self, y_true: np.array, y_pred: np.array, verbose: bool = False) -> float:\n",
    "        score = metrics.accuracy_score(y_true, y_pred)\n",
    "        if verbose:\n",
    "            print(f\"Score: {score:<.5f}\")\n",
    "        return score\n",
    "\n",
    "\n",
    "class TrainRunner(BaseRunner):\n",
    "    def _train_epoch(self, train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "        losses = AverageMeter()\n",
    "        model.train()\n",
    "        for _ in range(self.cfg.params.num_aug):\n",
    "            for step, image_label_dict in enumerate(train_loader):\n",
    "                images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "                labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "                batch_size = labels.size(0)\n",
    "\n",
    "                y_preds = model(images)\n",
    "                loss = criterion(y_preds, labels)\n",
    "                losses.update(loss.item(), batch_size)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        return losses.avg\n",
    "\n",
    "    def _valid_epoch(self, valid_loader, model, criterion):\n",
    "        losses = AverageMeter()\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for _, image_label_dict in enumerate(valid_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            labels = image_label_dict.get(\"label\").to(self.cfg.basic.device)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds).reshape(-1, self.params.target_size)\n",
    "        return losses.avg, predictions\n",
    "\n",
    "    def _train(self, train: pd.DataFrame, n_fold: int) -> pd.DataFrame:\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        train_images = load_npz(InputPath.train_images)\n",
    "        train_labels = load_npz(InputPath.train_labels)        \n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "\n",
    "        trn_idx = train[train[\"fold\"] != n_fold].index.tolist()\n",
    "        val_idx = train[train[\"fold\"] == n_fold].index.tolist()\n",
    "        train_images_folds = train_images[trn_idx]\n",
    "        valid_images_folds = train_images[val_idx]\n",
    "        train_labels_folds = train_labels[trn_idx]\n",
    "        valid_labels_folds = train_labels[val_idx]\n",
    "        train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "        valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "        train_dataset = ProbSpaceDataset(\n",
    "            train_images_folds,\n",
    "            train_labels_folds,\n",
    "            is_train=True,\n",
    "#             transform=get_transforms(self.params, data=\"train\"),\n",
    "        )\n",
    "        valid_dataset = ProbSpaceDataset(\n",
    "            valid_images_folds,\n",
    "            valid_labels_folds,\n",
    "            is_train=is_tta_mode,\n",
    "#             transform=get_transforms(self.params, data=\"valid\"),\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        # 少数クラスほど重みをつける\n",
    "        weights = 1 / np.array([Counter(train_labels_folds)[i] for i in range(self.params.target_size)])\n",
    "        weights = weights / np.sum(weights)\n",
    "        assert np.all(weights != 0) \n",
    "        weights = torch.tensor(weights).float().to(self.cfg.basic.device)\n",
    "\n",
    "        model = build_model(model_config=self.cfg)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=self.params.optimizer.lr,\n",
    "            weight_decay=self.params.optimizer.weight_decay,\n",
    "            amsgrad=self.params.optimizer.amsgrad,\n",
    "        )\n",
    "        scheduler = self._get_scheduler(optimizer)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        best_model = None\n",
    "        best_preds = None\n",
    "        best_score = 0\n",
    "        scores: List[float] = []\n",
    "        num_not_improved = 0\n",
    "        for epoch in range(self.params.epochs):\n",
    "            start_time = time.time()\n",
    "\n",
    "            avg_loss = self._train_epoch(\n",
    "                train_loader, model, criterion, optimizer, scheduler, epoch\n",
    "            )\n",
    "            avg_val_loss_list: List[float] = []\n",
    "            preds_array = np.zeros((num_times_tta, len(val_idx), self.params.target_size))\n",
    "            for i in range(num_times_tta):\n",
    "                avg_val_loss, preds = self._valid_epoch(valid_loader, model, criterion)\n",
    "                avg_val_loss_list.append(avg_val_loss)\n",
    "                preds_array[i] = preds\n",
    "            avg_val_loss = np.mean(avg_val_loss_list)\n",
    "            scheduler = self._step_scheduler(scheduler, avg_val_loss)\n",
    "\n",
    "            preds = preds_array.mean(axis=0)\n",
    "            preds_ = np.argmax(preds, axis=1)\n",
    "            valid_labels = valid_folds[\"target\"].values\n",
    "            score = self._evaluate(valid_labels, preds_)\n",
    "            scores.append(score)\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "            )\n",
    "            print(f\"Epoch {epoch+1} - Accuracy: {score}\")\n",
    "            if score > best_score:\n",
    "                best_model = model\n",
    "                best_preds = preds\n",
    "                best_score = score\n",
    "                num_not_improved = 0\n",
    "            else:\n",
    "                num_not_improved += 1\n",
    "            print(\n",
    "                f\"Epoch {epoch+1} - Best Score: {best_score:.4f}\"\n",
    "            )\n",
    "            if self.params.early_stopping_rounds > 0 and self.params.early_stopping_rounds == num_not_improved:\n",
    "                print(f\"Early stopping break: not improved {num_not_improved} times in a row\")\n",
    "                break\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": best_model.state_dict(), \n",
    "                \"preds\": best_preds, \n",
    "                \"best_score\": best_score, \n",
    "                \"scores\": scores\n",
    "            },\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\",\n",
    "        )\n",
    "        check_point: Dict[str, Union[OrderedDict, torch.Tensor]] = torch.load(\n",
    "            f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\"\n",
    "        )\n",
    "        valid_folds[\"preds\"] = np.argmax(check_point[\"preds\"], axis=1)\n",
    "        return valid_folds\n",
    "\n",
    "    def run_cv(self, train: pd.DataFrame) -> None:\n",
    "        print(f\"debug mode: {self.cfg.basic.is_debug}\")\n",
    "        print(f\"start time: {datetime.datetime.now()}\")\n",
    "        oof_df = pd.DataFrame()\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            _oof_df = self._train(train, n_fold)\n",
    "            print(f\"========== fold: {n_fold} result ==========\")\n",
    "            self._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"], verbose=True)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "        print(\"========== CV ==========\")\n",
    "        self._evaluate(oof_df[\"target\"], oof_df[\"preds\"], verbose=True)\n",
    "        Jbl.save(oof_df, f\"{OutputPath.model}/oof_df_{self.cfg.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c6ec55-378b-402c-8f5b-00172c78fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRunner(BaseRunner):\n",
    "    def _test_epoch(self, test_loader, model):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, image_label_dict in enumerate(test_loader):\n",
    "            images = image_label_dict.get(\"image\").to(self.cfg.basic.device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "        predictions = np.concatenate(preds).reshape(-1, self.params.target_size)\n",
    "        return predictions\n",
    "\n",
    "    def _test(self, test: pd.DataFrame, n_fold: int):\n",
    "        print(f\"fold: {n_fold}\")\n",
    "        test_images = load_npz(input_path.test_images)\n",
    "        \n",
    "        is_tta_mode = self.params.num_tta > 0\n",
    "        num_times_tta = 1 if not is_tta_mode else self.params.num_tta\n",
    "        \n",
    "        test_dataset = ProbSpaceDataset(\n",
    "            test_images,\n",
    "            is_train=False,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.params.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        model = build_model(model_config=self.cfg)\n",
    "        model_state = torch.load(f\"{OutputPath.model}/{self.cfg.basic.run_name}_{n_fold}.pth\")[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(self.cfg.basic.device)\n",
    "        # preds = self._test_epoch(test_loader, model)\n",
    "        preds_array = np.zeros((num_times_tta, len(test_images), self.params.target_size))\n",
    "        for i in range(num_times_tta):\n",
    "            _preds = self._test_epoch(test_loader, model)\n",
    "            preds_array[i] = _preds\n",
    "        preds = preds_array.mean(axis=0)\n",
    "        return preds\n",
    "    \n",
    "    def _submit(self, preds: np.array) -> None:\n",
    "        test_images = load_npz(input_path.test_images)\n",
    "        df_sub = pd.DataFrame({\"id\": list(range(len(test_images)))})\n",
    "        df_sub = df_sub.assign(y=preds)\n",
    "        print(df_sub.head())\n",
    "        df_sub = df_sub.astype(int)\n",
    "        path = f\"{OutputPath.submission}/submission_{self.cfg.basic.run_name}.csv\"\n",
    "        df_sub.to_csv(path, index=False)\n",
    "        print(\"submission.csv created\")\n",
    "\n",
    "    def run_cv(self, test: pd.DataFrame = None) -> None:\n",
    "        oof_df = pd.DataFrame()\n",
    "        preds: List[np.array] = []\n",
    "        for n_fold in range(self.cfg.kfold.number):\n",
    "            preds_fold = self._test(test, n_fold)\n",
    "            preds.append(preds_fold)\n",
    "        Jbl.save(preds, f\"{OutputPath.model}/preds_test_{self.cfg.basic.run_name}.jbl\")\n",
    "        \n",
    "        preds_mean = np.mean(preds, axis=0)\n",
    "        assert preds_mean.shape == (497, 13)\n",
    "        preds_mean = preds_mean.argmax(axis=1)\n",
    "        assert preds_mean.shape == (497,)\n",
    "        self._submit(preds_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae1cb89-4ee0-4293-b935-888a14f628da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed()\n",
    "input_path = InputPath()\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99fafc2-2ace-488f-b2a3-1f6f3297af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = load_npz(InputPath.train_labels)\n",
    "\n",
    "train = pd.DataFrame({\"target\": train_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8796a89d-9fce-49b6-8d53-3c315b65722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - [1 2 3 6 7]~[645 646 648 651 653] (523)\t[ 0  4  5 11 17]~[644 647 649 650 652] (131)\n",
      "fold: 1 - [0 1 2 4 5]~[649 650 651 652 653] (523)\t[ 3  6  8  9 12]~[636 638 641 645 648] (131)\n",
      "fold: 2 - [0 1 3 4 5]~[649 650 651 652 653] (523)\t[ 2 13 14 18 21]~[629 631 632 633 646] (131)\n",
      "fold: 3 - [0 2 3 4 5]~[648 649 650 651 652] (523)\t[ 1 10 15 16 27]~[611 614 628 639 653] (131)\n",
      "fold: 4 - [0 1 2 3 4]~[648 649 650 652 653] (524)\t[ 7 22 23 24 25]~[622 635 637 643 651] (130)\n"
     ]
    }
   ],
   "source": [
    "kf = generate_kf(model_config)\n",
    "if model_config.kfold.method.endswith(\"gkf\"):\n",
    "    kf_generator = kf.split(\n",
    "        train,\n",
    "        train[self.fe_cfg.column.target],\n",
    "        groups=train[self.kfold.columns],\n",
    "    )\n",
    "else:\n",
    "    kf_generator = kf.split(train, train[\"target\"])\n",
    "for fold_i, (tr_idx, val_idx) in enumerate(kf_generator):\n",
    "    print(\n",
    "        f\"fold: {fold_i} - {tr_idx[:5]}~{tr_idx[-5:]} ({len(tr_idx)})\\t{val_idx[:5]}~{val_idx[-5:]} ({len(val_idx)})\"\n",
    "    )\n",
    "    train.loc[val_idx, \"fold\"] = fold_i\n",
    "train = train.assign(fold = train[\"fold\"].astype(int))\n",
    "# if model_config.kfold.method == \"skf\":\n",
    "#     pd.set_option(\"display.max_rows\", 65)\n",
    "#     display(train.groupby([\"fold\", \"target\"]).size().to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7747e0-4b47-4f29-9555-80495b4adffd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug mode: False\n",
      "start time: 2021-08-08 13:33:01.583638\n",
      "fold: 0\n",
      "Epoch 1 - avg_train_loss: 2.5572  avg_val_loss: 2.5557  time: 68s\n",
      "Epoch 1 - Accuracy: 0.25190839694656486\n",
      "Epoch 1 - Best Score: 0.2519\n",
      "Epoch 2 - avg_train_loss: 2.4963  avg_val_loss: 2.5072  time: 69s\n",
      "Epoch 2 - Accuracy: 0.26717557251908397\n",
      "Epoch 2 - Best Score: 0.2672\n",
      "Epoch 3 - avg_train_loss: 2.4052  avg_val_loss: 2.4747  time: 69s\n",
      "Epoch 3 - Accuracy: 0.32061068702290074\n",
      "Epoch 3 - Best Score: 0.3206\n",
      "Epoch 4 - avg_train_loss: 2.3507  avg_val_loss: 2.4500  time: 69s\n",
      "Epoch 4 - Accuracy: 0.37404580152671757\n",
      "Epoch 4 - Best Score: 0.3740\n",
      "Epoch 5 - avg_train_loss: 2.2843  avg_val_loss: 2.4496  time: 69s\n",
      "Epoch 5 - Accuracy: 0.35877862595419846\n",
      "Epoch 5 - Best Score: 0.3740\n",
      "Epoch 6 - avg_train_loss: 2.2291  avg_val_loss: 2.4064  time: 69s\n",
      "Epoch 6 - Accuracy: 0.40458015267175573\n",
      "Epoch 6 - Best Score: 0.4046\n",
      "Epoch 7 - avg_train_loss: 2.1711  avg_val_loss: 2.3647  time: 69s\n",
      "Epoch 7 - Accuracy: 0.45038167938931295\n",
      "Epoch 7 - Best Score: 0.4504\n",
      "Epoch 8 - avg_train_loss: 2.1107  avg_val_loss: 2.3475  time: 69s\n",
      "Epoch 8 - Accuracy: 0.45038167938931295\n",
      "Epoch 8 - Best Score: 0.4504\n",
      "Epoch 9 - avg_train_loss: 2.0855  avg_val_loss: 2.3068  time: 69s\n",
      "Epoch 9 - Accuracy: 0.5038167938931297\n",
      "Epoch 9 - Best Score: 0.5038\n",
      "Epoch 10 - avg_train_loss: 2.0422  avg_val_loss: 2.3147  time: 69s\n",
      "Epoch 10 - Accuracy: 0.4580152671755725\n",
      "Epoch 10 - Best Score: 0.5038\n",
      "Epoch 11 - avg_train_loss: 2.0066  avg_val_loss: 2.3142  time: 69s\n",
      "Epoch 11 - Accuracy: 0.5267175572519084\n",
      "Epoch 11 - Best Score: 0.5267\n",
      "Epoch 12 - avg_train_loss: 1.9822  avg_val_loss: 2.2718  time: 69s\n",
      "Epoch 12 - Accuracy: 0.549618320610687\n",
      "Epoch 12 - Best Score: 0.5496\n",
      "Epoch 13 - avg_train_loss: 1.9551  avg_val_loss: 2.2344  time: 69s\n",
      "Epoch 13 - Accuracy: 0.5648854961832062\n",
      "Epoch 13 - Best Score: 0.5649\n",
      "Epoch 14 - avg_train_loss: 1.9252  avg_val_loss: 2.2764  time: 69s\n",
      "Epoch 14 - Accuracy: 0.5419847328244275\n",
      "Epoch 14 - Best Score: 0.5649\n",
      "Epoch 15 - avg_train_loss: 1.9213  avg_val_loss: 2.2641  time: 69s\n",
      "Epoch 15 - Accuracy: 0.5572519083969466\n",
      "Epoch 15 - Best Score: 0.5649\n",
      "Epoch 16 - avg_train_loss: 1.8923  avg_val_loss: 2.2751  time: 69s\n",
      "Epoch 16 - Accuracy: 0.4961832061068702\n",
      "Epoch 16 - Best Score: 0.5649\n",
      "Epoch 17 - avg_train_loss: 1.8909  avg_val_loss: 2.2723  time: 69s\n",
      "Epoch 17 - Accuracy: 0.5267175572519084\n",
      "Epoch 17 - Best Score: 0.5649\n",
      "Epoch 18 - avg_train_loss: 1.8749  avg_val_loss: 2.2641  time: 69s\n",
      "Epoch 18 - Accuracy: 0.5419847328244275\n",
      "Epoch 18 - Best Score: 0.5649\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 19 - avg_train_loss: 1.8564  avg_val_loss: 2.2583  time: 69s\n",
      "Epoch 19 - Accuracy: 0.5572519083969466\n",
      "Epoch 19 - Best Score: 0.5649\n",
      "Epoch 20 - avg_train_loss: 1.8478  avg_val_loss: 2.2470  time: 69s\n",
      "Epoch 20 - Accuracy: 0.5267175572519084\n",
      "Epoch 20 - Best Score: 0.5649\n",
      "Epoch 21 - avg_train_loss: 1.8461  avg_val_loss: 2.2418  time: 69s\n",
      "Epoch 21 - Accuracy: 0.5648854961832062\n",
      "Epoch 21 - Best Score: 0.5649\n",
      "Epoch 22 - avg_train_loss: 1.8374  avg_val_loss: 2.2370  time: 69s\n",
      "Epoch 22 - Accuracy: 0.5877862595419847\n",
      "Epoch 22 - Best Score: 0.5878\n",
      "Epoch 23 - avg_train_loss: 1.8411  avg_val_loss: 2.2626  time: 69s\n",
      "Epoch 23 - Accuracy: 0.5038167938931297\n",
      "Epoch 23 - Best Score: 0.5878\n",
      "Epoch 24 - avg_train_loss: 1.8385  avg_val_loss: 2.2537  time: 69s\n",
      "Epoch 24 - Accuracy: 0.5343511450381679\n",
      "Epoch 24 - Best Score: 0.5878\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 25 - avg_train_loss: 1.8364  avg_val_loss: 2.2516  time: 69s\n",
      "Epoch 25 - Accuracy: 0.5343511450381679\n",
      "Epoch 25 - Best Score: 0.5878\n",
      "Epoch 26 - avg_train_loss: 1.8391  avg_val_loss: 2.2319  time: 69s\n",
      "Epoch 26 - Accuracy: 0.5725190839694656\n",
      "Epoch 26 - Best Score: 0.5878\n",
      "Epoch 27 - avg_train_loss: 1.8304  avg_val_loss: 2.2476  time: 69s\n",
      "Epoch 27 - Accuracy: 0.5343511450381679\n",
      "Epoch 27 - Best Score: 0.5878\n",
      "Epoch 28 - avg_train_loss: 1.8271  avg_val_loss: 2.2423  time: 69s\n",
      "Epoch 28 - Accuracy: 0.5343511450381679\n",
      "Epoch 28 - Best Score: 0.5878\n",
      "Epoch 29 - avg_train_loss: 1.8415  avg_val_loss: 2.2392  time: 69s\n",
      "Epoch 29 - Accuracy: 0.5419847328244275\n",
      "Epoch 29 - Best Score: 0.5878\n",
      "Epoch 30 - avg_train_loss: 1.8276  avg_val_loss: 2.2366  time: 69s\n",
      "Epoch 30 - Accuracy: 0.5419847328244275\n",
      "Epoch 30 - Best Score: 0.5878\n",
      "Epoch 31 - avg_train_loss: 1.8387  avg_val_loss: 2.2679  time: 69s\n",
      "Epoch 31 - Accuracy: 0.549618320610687\n",
      "Epoch 31 - Best Score: 0.5878\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 32 - avg_train_loss: 1.8240  avg_val_loss: 2.2606  time: 69s\n",
      "Epoch 32 - Accuracy: 0.549618320610687\n",
      "Epoch 32 - Best Score: 0.5878\n",
      "Epoch 33 - avg_train_loss: 1.8330  avg_val_loss: 2.2648  time: 69s\n",
      "Epoch 33 - Accuracy: 0.5038167938931297\n",
      "Epoch 33 - Best Score: 0.5878\n",
      "Epoch 34 - avg_train_loss: 1.8236  avg_val_loss: 2.2571  time: 69s\n",
      "Epoch 34 - Accuracy: 0.549618320610687\n",
      "Epoch 34 - Best Score: 0.5878\n",
      "Epoch 35 - avg_train_loss: 1.8202  avg_val_loss: 2.2424  time: 69s\n",
      "Epoch 35 - Accuracy: 0.5648854961832062\n",
      "Epoch 35 - Best Score: 0.5878\n",
      "Epoch 36 - avg_train_loss: 1.8226  avg_val_loss: 2.2323  time: 69s\n",
      "Epoch 36 - Accuracy: 0.5572519083969466\n",
      "Epoch 36 - Best Score: 0.5878\n",
      "Epoch 37 - avg_train_loss: 1.8317  avg_val_loss: 2.2454  time: 69s\n",
      "Epoch 37 - Accuracy: 0.5648854961832062\n",
      "Epoch 37 - Best Score: 0.5878\n",
      "Epoch 38 - avg_train_loss: 1.8297  avg_val_loss: 2.2313  time: 69s\n",
      "Epoch 38 - Accuracy: 0.5343511450381679\n",
      "Epoch 38 - Best Score: 0.5878\n",
      "Epoch 39 - avg_train_loss: 1.8324  avg_val_loss: 2.2540  time: 69s\n",
      "Epoch 39 - Accuracy: 0.5572519083969466\n",
      "Epoch 39 - Best Score: 0.5878\n",
      "Epoch 40 - avg_train_loss: 1.8354  avg_val_loss: 2.2549  time: 69s\n",
      "Epoch 40 - Accuracy: 0.5648854961832062\n",
      "Epoch 40 - Best Score: 0.5878\n",
      "Epoch 41 - avg_train_loss: 1.8345  avg_val_loss: 2.2462  time: 69s\n",
      "Epoch 41 - Accuracy: 0.5419847328244275\n",
      "Epoch 41 - Best Score: 0.5878\n",
      "Epoch 42 - avg_train_loss: 1.8482  avg_val_loss: 2.2453  time: 69s\n",
      "Epoch 42 - Accuracy: 0.549618320610687\n",
      "Epoch 42 - Best Score: 0.5878\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.58779\n",
      "fold: 1\n",
      "Epoch 1 - avg_train_loss: 2.5566  avg_val_loss: 2.5533  time: 69s\n",
      "Epoch 1 - Accuracy: 0.0916030534351145\n",
      "Epoch 1 - Best Score: 0.0916\n",
      "Epoch 2 - avg_train_loss: 2.5011  avg_val_loss: 2.5183  time: 69s\n",
      "Epoch 2 - Accuracy: 0.1450381679389313\n",
      "Epoch 2 - Best Score: 0.1450\n",
      "Epoch 3 - avg_train_loss: 2.4320  avg_val_loss: 2.4828  time: 69s\n",
      "Epoch 3 - Accuracy: 0.1984732824427481\n",
      "Epoch 3 - Best Score: 0.1985\n",
      "Epoch 4 - avg_train_loss: 2.3654  avg_val_loss: 2.4373  time: 70s\n",
      "Epoch 4 - Accuracy: 0.26717557251908397\n",
      "Epoch 4 - Best Score: 0.2672\n",
      "Epoch 5 - avg_train_loss: 2.2774  avg_val_loss: 2.4139  time: 69s\n",
      "Epoch 5 - Accuracy: 0.3435114503816794\n",
      "Epoch 5 - Best Score: 0.3435\n",
      "Epoch 6 - avg_train_loss: 2.2077  avg_val_loss: 2.4074  time: 69s\n",
      "Epoch 6 - Accuracy: 0.3282442748091603\n",
      "Epoch 6 - Best Score: 0.3435\n",
      "Epoch 7 - avg_train_loss: 2.1612  avg_val_loss: 2.3924  time: 69s\n",
      "Epoch 7 - Accuracy: 0.32061068702290074\n",
      "Epoch 7 - Best Score: 0.3435\n",
      "Epoch 8 - avg_train_loss: 2.1225  avg_val_loss: 2.3574  time: 69s\n",
      "Epoch 8 - Accuracy: 0.3969465648854962\n",
      "Epoch 8 - Best Score: 0.3969\n",
      "Epoch 9 - avg_train_loss: 2.0828  avg_val_loss: 2.3302  time: 69s\n",
      "Epoch 9 - Accuracy: 0.3893129770992366\n",
      "Epoch 9 - Best Score: 0.3969\n",
      "Epoch 10 - avg_train_loss: 2.0408  avg_val_loss: 2.3267  time: 70s\n",
      "Epoch 10 - Accuracy: 0.40458015267175573\n",
      "Epoch 10 - Best Score: 0.4046\n",
      "Epoch 11 - avg_train_loss: 2.0031  avg_val_loss: 2.2831  time: 69s\n",
      "Epoch 11 - Accuracy: 0.5114503816793893\n",
      "Epoch 11 - Best Score: 0.5115\n",
      "Epoch 12 - avg_train_loss: 1.9686  avg_val_loss: 2.3188  time: 70s\n",
      "Epoch 12 - Accuracy: 0.44274809160305345\n",
      "Epoch 12 - Best Score: 0.5115\n",
      "Epoch 13 - avg_train_loss: 1.9595  avg_val_loss: 2.3161  time: 69s\n",
      "Epoch 13 - Accuracy: 0.44274809160305345\n",
      "Epoch 13 - Best Score: 0.5115\n",
      "Epoch 14 - avg_train_loss: 1.9306  avg_val_loss: 2.3030  time: 69s\n",
      "Epoch 14 - Accuracy: 0.4961832061068702\n",
      "Epoch 14 - Best Score: 0.5115\n",
      "Epoch 15 - avg_train_loss: 1.9125  avg_val_loss: 2.2924  time: 69s\n",
      "Epoch 15 - Accuracy: 0.5114503816793893\n",
      "Epoch 15 - Best Score: 0.5115\n",
      "Epoch 16 - avg_train_loss: 1.9071  avg_val_loss: 2.2696  time: 70s\n",
      "Epoch 16 - Accuracy: 0.5114503816793893\n",
      "Epoch 16 - Best Score: 0.5115\n",
      "Epoch 17 - avg_train_loss: 1.8873  avg_val_loss: 2.2853  time: 70s\n",
      "Epoch 17 - Accuracy: 0.48091603053435117\n",
      "Epoch 17 - Best Score: 0.5115\n",
      "Epoch 18 - avg_train_loss: 1.8768  avg_val_loss: 2.2846  time: 70s\n",
      "Epoch 18 - Accuracy: 0.5038167938931297\n",
      "Epoch 18 - Best Score: 0.5115\n",
      "Epoch 19 - avg_train_loss: 1.8569  avg_val_loss: 2.2842  time: 70s\n",
      "Epoch 19 - Accuracy: 0.45038167938931295\n",
      "Epoch 19 - Best Score: 0.5115\n",
      "Epoch 20 - avg_train_loss: 1.8554  avg_val_loss: 2.2680  time: 69s\n",
      "Epoch 20 - Accuracy: 0.5038167938931297\n",
      "Epoch 20 - Best Score: 0.5115\n",
      "Epoch 21 - avg_train_loss: 1.8395  avg_val_loss: 2.2707  time: 70s\n",
      "Epoch 21 - Accuracy: 0.5114503816793893\n",
      "Epoch 21 - Best Score: 0.5115\n",
      "Epoch 22 - avg_train_loss: 1.8343  avg_val_loss: 2.2898  time: 70s\n",
      "Epoch 22 - Accuracy: 0.44274809160305345\n",
      "Epoch 22 - Best Score: 0.5115\n",
      "Epoch 23 - avg_train_loss: 1.8307  avg_val_loss: 2.2835  time: 70s\n",
      "Epoch 23 - Accuracy: 0.48091603053435117\n",
      "Epoch 23 - Best Score: 0.5115\n",
      "Epoch 24 - avg_train_loss: 1.8376  avg_val_loss: 2.2758  time: 69s\n",
      "Epoch 24 - Accuracy: 0.48091603053435117\n",
      "Epoch 24 - Best Score: 0.5115\n",
      "Epoch 25 - avg_train_loss: 1.8167  avg_val_loss: 2.2704  time: 69s\n",
      "Epoch 25 - Accuracy: 0.48091603053435117\n",
      "Epoch 25 - Best Score: 0.5115\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 26 - avg_train_loss: 1.8153  avg_val_loss: 2.2683  time: 69s\n",
      "Epoch 26 - Accuracy: 0.5114503816793893\n",
      "Epoch 26 - Best Score: 0.5115\n",
      "Epoch 27 - avg_train_loss: 1.8161  avg_val_loss: 2.2624  time: 69s\n",
      "Epoch 27 - Accuracy: 0.5114503816793893\n",
      "Epoch 27 - Best Score: 0.5115\n",
      "Epoch 28 - avg_train_loss: 1.8151  avg_val_loss: 2.2540  time: 69s\n",
      "Epoch 28 - Accuracy: 0.5114503816793893\n",
      "Epoch 28 - Best Score: 0.5115\n",
      "Epoch 29 - avg_train_loss: 1.8178  avg_val_loss: 2.2550  time: 69s\n",
      "Epoch 29 - Accuracy: 0.4961832061068702\n",
      "Epoch 29 - Best Score: 0.5115\n",
      "Epoch 30 - avg_train_loss: 1.8116  avg_val_loss: 2.2445  time: 69s\n",
      "Epoch 30 - Accuracy: 0.5419847328244275\n",
      "Epoch 30 - Best Score: 0.5420\n",
      "Epoch 31 - avg_train_loss: 1.7986  avg_val_loss: 2.2534  time: 70s\n",
      "Epoch 31 - Accuracy: 0.5419847328244275\n",
      "Epoch 31 - Best Score: 0.5420\n",
      "Epoch 32 - avg_train_loss: 1.7920  avg_val_loss: 2.2676  time: 70s\n",
      "Epoch 32 - Accuracy: 0.5038167938931297\n",
      "Epoch 32 - Best Score: 0.5420\n",
      "Epoch 33 - avg_train_loss: 1.7963  avg_val_loss: 2.2239  time: 69s\n",
      "Epoch 33 - Accuracy: 0.549618320610687\n",
      "Epoch 33 - Best Score: 0.5496\n",
      "Epoch 34 - avg_train_loss: 1.8081  avg_val_loss: 2.2717  time: 69s\n",
      "Epoch 34 - Accuracy: 0.5190839694656488\n",
      "Epoch 34 - Best Score: 0.5496\n",
      "Epoch 35 - avg_train_loss: 1.7994  avg_val_loss: 2.2482  time: 70s\n",
      "Epoch 35 - Accuracy: 0.5267175572519084\n",
      "Epoch 35 - Best Score: 0.5496\n",
      "Epoch 36 - avg_train_loss: 1.7969  avg_val_loss: 2.2555  time: 70s\n",
      "Epoch 36 - Accuracy: 0.5114503816793893\n",
      "Epoch 36 - Best Score: 0.5496\n",
      "Epoch 37 - avg_train_loss: 1.7921  avg_val_loss: 2.2570  time: 69s\n",
      "Epoch 37 - Accuracy: 0.5114503816793893\n",
      "Epoch 37 - Best Score: 0.5496\n",
      "Epoch 38 - avg_train_loss: 1.8003  avg_val_loss: 2.2531  time: 69s\n",
      "Epoch 38 - Accuracy: 0.5038167938931297\n",
      "Epoch 38 - Best Score: 0.5496\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 39 - avg_train_loss: 1.7958  avg_val_loss: 2.2761  time: 69s\n",
      "Epoch 39 - Accuracy: 0.48091603053435117\n",
      "Epoch 39 - Best Score: 0.5496\n",
      "Epoch 40 - avg_train_loss: 1.7931  avg_val_loss: 2.2697  time: 69s\n",
      "Epoch 40 - Accuracy: 0.5267175572519084\n",
      "Epoch 40 - Best Score: 0.5496\n",
      "Epoch 41 - avg_train_loss: 1.7908  avg_val_loss: 2.2649  time: 70s\n",
      "Epoch 41 - Accuracy: 0.48854961832061067\n",
      "Epoch 41 - Best Score: 0.5496\n",
      "Epoch 42 - avg_train_loss: 1.8010  avg_val_loss: 2.2589  time: 69s\n",
      "Epoch 42 - Accuracy: 0.5190839694656488\n",
      "Epoch 42 - Best Score: 0.5496\n",
      "Epoch 43 - avg_train_loss: 1.7920  avg_val_loss: 2.2583  time: 69s\n",
      "Epoch 43 - Accuracy: 0.5190839694656488\n",
      "Epoch 43 - Best Score: 0.5496\n",
      "Epoch 44 - avg_train_loss: 1.7943  avg_val_loss: 2.2540  time: 70s\n",
      "Epoch 44 - Accuracy: 0.5267175572519084\n",
      "Epoch 44 - Best Score: 0.5496\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 45 - avg_train_loss: 1.7921  avg_val_loss: 2.2551  time: 70s\n",
      "Epoch 45 - Accuracy: 0.5114503816793893\n",
      "Epoch 45 - Best Score: 0.5496\n",
      "Epoch 46 - avg_train_loss: 1.7915  avg_val_loss: 2.2462  time: 69s\n",
      "Epoch 46 - Accuracy: 0.5038167938931297\n",
      "Epoch 46 - Best Score: 0.5496\n",
      "Epoch 47 - avg_train_loss: 1.7956  avg_val_loss: 2.2654  time: 69s\n",
      "Epoch 47 - Accuracy: 0.48091603053435117\n",
      "Epoch 47 - Best Score: 0.5496\n",
      "Epoch 48 - avg_train_loss: 1.7880  avg_val_loss: 2.2494  time: 70s\n",
      "Epoch 48 - Accuracy: 0.5343511450381679\n",
      "Epoch 48 - Best Score: 0.5496\n",
      "Epoch 49 - avg_train_loss: 1.7959  avg_val_loss: 2.2549  time: 69s\n",
      "Epoch 49 - Accuracy: 0.5114503816793893\n",
      "Epoch 49 - Best Score: 0.5496\n",
      "Epoch 50 - avg_train_loss: 1.7934  avg_val_loss: 2.2426  time: 70s\n",
      "Epoch 50 - Accuracy: 0.5419847328244275\n",
      "Epoch 50 - Best Score: 0.5496\n",
      "Epoch 51 - avg_train_loss: 1.7930  avg_val_loss: 2.2596  time: 70s\n",
      "Epoch 51 - Accuracy: 0.5114503816793893\n",
      "Epoch 51 - Best Score: 0.5496\n",
      "Epoch 52 - avg_train_loss: 1.7943  avg_val_loss: 2.2540  time: 69s\n",
      "Epoch 52 - Accuracy: 0.549618320610687\n",
      "Epoch 52 - Best Score: 0.5496\n",
      "Epoch 53 - avg_train_loss: 1.7891  avg_val_loss: 2.2505  time: 69s\n",
      "Epoch 53 - Accuracy: 0.5419847328244275\n",
      "Epoch 53 - Best Score: 0.5496\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 1 result ==========\n",
      "Score: 0.54962\n",
      "fold: 2\n",
      "Epoch 1 - avg_train_loss: 2.5563  avg_val_loss: 2.5458  time: 69s\n",
      "Epoch 1 - Accuracy: 0.21374045801526717\n",
      "Epoch 1 - Best Score: 0.2137\n",
      "Epoch 2 - avg_train_loss: 2.5054  avg_val_loss: 2.4960  time: 69s\n",
      "Epoch 2 - Accuracy: 0.25190839694656486\n",
      "Epoch 2 - Best Score: 0.2519\n",
      "Epoch 3 - avg_train_loss: 2.4437  avg_val_loss: 2.4520  time: 69s\n",
      "Epoch 3 - Accuracy: 0.26717557251908397\n",
      "Epoch 3 - Best Score: 0.2672\n",
      "Epoch 4 - avg_train_loss: 2.3586  avg_val_loss: 2.4061  time: 69s\n",
      "Epoch 4 - Accuracy: 0.29770992366412213\n",
      "Epoch 4 - Best Score: 0.2977\n",
      "Epoch 5 - avg_train_loss: 2.2878  avg_val_loss: 2.3636  time: 69s\n",
      "Epoch 5 - Accuracy: 0.3816793893129771\n",
      "Epoch 5 - Best Score: 0.3817\n",
      "Epoch 6 - avg_train_loss: 2.2084  avg_val_loss: 2.3138  time: 70s\n",
      "Epoch 6 - Accuracy: 0.40458015267175573\n",
      "Epoch 6 - Best Score: 0.4046\n",
      "Epoch 7 - avg_train_loss: 2.1539  avg_val_loss: 2.3063  time: 69s\n",
      "Epoch 7 - Accuracy: 0.4198473282442748\n",
      "Epoch 7 - Best Score: 0.4198\n",
      "Epoch 8 - avg_train_loss: 2.1032  avg_val_loss: 2.2860  time: 69s\n",
      "Epoch 8 - Accuracy: 0.45038167938931295\n",
      "Epoch 8 - Best Score: 0.4504\n",
      "Epoch 9 - avg_train_loss: 2.0750  avg_val_loss: 2.2946  time: 69s\n",
      "Epoch 9 - Accuracy: 0.44274809160305345\n",
      "Epoch 9 - Best Score: 0.4504\n",
      "Epoch 10 - avg_train_loss: 2.0322  avg_val_loss: 2.2550  time: 69s\n",
      "Epoch 10 - Accuracy: 0.46564885496183206\n",
      "Epoch 10 - Best Score: 0.4656\n",
      "Epoch 11 - avg_train_loss: 2.0109  avg_val_loss: 2.2378  time: 69s\n",
      "Epoch 11 - Accuracy: 0.5190839694656488\n",
      "Epoch 11 - Best Score: 0.5191\n",
      "Epoch 12 - avg_train_loss: 1.9924  avg_val_loss: 2.2384  time: 69s\n",
      "Epoch 12 - Accuracy: 0.549618320610687\n",
      "Epoch 12 - Best Score: 0.5496\n",
      "Epoch 13 - avg_train_loss: 1.9606  avg_val_loss: 2.2223  time: 69s\n",
      "Epoch 13 - Accuracy: 0.5114503816793893\n",
      "Epoch 13 - Best Score: 0.5496\n",
      "Epoch 14 - avg_train_loss: 1.9343  avg_val_loss: 2.2429  time: 69s\n",
      "Epoch 14 - Accuracy: 0.4961832061068702\n",
      "Epoch 14 - Best Score: 0.5496\n",
      "Epoch 15 - avg_train_loss: 1.9141  avg_val_loss: 2.2268  time: 69s\n",
      "Epoch 15 - Accuracy: 0.5190839694656488\n",
      "Epoch 15 - Best Score: 0.5496\n",
      "Epoch 16 - avg_train_loss: 1.9039  avg_val_loss: 2.2254  time: 69s\n",
      "Epoch 16 - Accuracy: 0.5343511450381679\n",
      "Epoch 16 - Best Score: 0.5496\n",
      "Epoch 17 - avg_train_loss: 1.8840  avg_val_loss: 2.2387  time: 69s\n",
      "Epoch 17 - Accuracy: 0.5190839694656488\n",
      "Epoch 17 - Best Score: 0.5496\n",
      "Epoch 18 - avg_train_loss: 1.8783  avg_val_loss: 2.2021  time: 70s\n",
      "Epoch 18 - Accuracy: 0.5725190839694656\n",
      "Epoch 18 - Best Score: 0.5725\n",
      "Epoch 19 - avg_train_loss: 1.8621  avg_val_loss: 2.2191  time: 69s\n",
      "Epoch 19 - Accuracy: 0.5572519083969466\n",
      "Epoch 19 - Best Score: 0.5725\n",
      "Epoch 20 - avg_train_loss: 1.8549  avg_val_loss: 2.2211  time: 69s\n",
      "Epoch 20 - Accuracy: 0.5343511450381679\n",
      "Epoch 20 - Best Score: 0.5725\n",
      "Epoch 21 - avg_train_loss: 1.8414  avg_val_loss: 2.2047  time: 70s\n",
      "Epoch 21 - Accuracy: 0.5572519083969466\n",
      "Epoch 21 - Best Score: 0.5725\n",
      "Epoch 22 - avg_train_loss: 1.8425  avg_val_loss: 2.2106  time: 69s\n",
      "Epoch 22 - Accuracy: 0.5572519083969466\n",
      "Epoch 22 - Best Score: 0.5725\n",
      "Epoch 23 - avg_train_loss: 1.8265  avg_val_loss: 2.1972  time: 69s\n",
      "Epoch 23 - Accuracy: 0.549618320610687\n",
      "Epoch 23 - Best Score: 0.5725\n",
      "Epoch 24 - avg_train_loss: 1.8239  avg_val_loss: 2.2106  time: 69s\n",
      "Epoch 24 - Accuracy: 0.549618320610687\n",
      "Epoch 24 - Best Score: 0.5725\n",
      "Epoch 25 - avg_train_loss: 1.8205  avg_val_loss: 2.1977  time: 69s\n",
      "Epoch 25 - Accuracy: 0.5954198473282443\n",
      "Epoch 25 - Best Score: 0.5954\n",
      "Epoch 26 - avg_train_loss: 1.8200  avg_val_loss: 2.1982  time: 69s\n",
      "Epoch 26 - Accuracy: 0.5877862595419847\n",
      "Epoch 26 - Best Score: 0.5954\n",
      "Epoch 27 - avg_train_loss: 1.8116  avg_val_loss: 2.1761  time: 69s\n",
      "Epoch 27 - Accuracy: 0.6030534351145038\n",
      "Epoch 27 - Best Score: 0.6031\n",
      "Epoch 28 - avg_train_loss: 1.8081  avg_val_loss: 2.1985  time: 69s\n",
      "Epoch 28 - Accuracy: 0.5725190839694656\n",
      "Epoch 28 - Best Score: 0.6031\n",
      "Epoch 29 - avg_train_loss: 1.8122  avg_val_loss: 2.2073  time: 70s\n",
      "Epoch 29 - Accuracy: 0.6030534351145038\n",
      "Epoch 29 - Best Score: 0.6031\n",
      "Epoch 30 - avg_train_loss: 1.7985  avg_val_loss: 2.2028  time: 69s\n",
      "Epoch 30 - Accuracy: 0.5648854961832062\n",
      "Epoch 30 - Best Score: 0.6031\n",
      "Epoch 31 - avg_train_loss: 1.7927  avg_val_loss: 2.1950  time: 69s\n",
      "Epoch 31 - Accuracy: 0.5725190839694656\n",
      "Epoch 31 - Best Score: 0.6031\n",
      "Epoch 32 - avg_train_loss: 1.7961  avg_val_loss: 2.1931  time: 69s\n",
      "Epoch 32 - Accuracy: 0.5419847328244275\n",
      "Epoch 32 - Best Score: 0.6031\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 33 - avg_train_loss: 1.7863  avg_val_loss: 2.2102  time: 69s\n",
      "Epoch 33 - Accuracy: 0.6106870229007634\n",
      "Epoch 33 - Best Score: 0.6107\n",
      "Epoch 34 - avg_train_loss: 1.7854  avg_val_loss: 2.1963  time: 69s\n",
      "Epoch 34 - Accuracy: 0.5648854961832062\n",
      "Epoch 34 - Best Score: 0.6107\n",
      "Epoch 35 - avg_train_loss: 1.7836  avg_val_loss: 2.2075  time: 69s\n",
      "Epoch 35 - Accuracy: 0.5572519083969466\n",
      "Epoch 35 - Best Score: 0.6107\n",
      "Epoch 36 - avg_train_loss: 1.7805  avg_val_loss: 2.1859  time: 69s\n",
      "Epoch 36 - Accuracy: 0.5725190839694656\n",
      "Epoch 36 - Best Score: 0.6107\n",
      "Epoch 37 - avg_train_loss: 1.7821  avg_val_loss: 2.1764  time: 69s\n",
      "Epoch 37 - Accuracy: 0.6183206106870229\n",
      "Epoch 37 - Best Score: 0.6183\n",
      "Epoch 38 - avg_train_loss: 1.7793  avg_val_loss: 2.1897  time: 69s\n",
      "Epoch 38 - Accuracy: 0.6106870229007634\n",
      "Epoch 38 - Best Score: 0.6183\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 39 - avg_train_loss: 1.7737  avg_val_loss: 2.1992  time: 70s\n",
      "Epoch 39 - Accuracy: 0.549618320610687\n",
      "Epoch 39 - Best Score: 0.6183\n",
      "Epoch 40 - avg_train_loss: 1.7751  avg_val_loss: 2.1796  time: 70s\n",
      "Epoch 40 - Accuracy: 0.5954198473282443\n",
      "Epoch 40 - Best Score: 0.6183\n",
      "Epoch 41 - avg_train_loss: 1.7837  avg_val_loss: 2.1678  time: 70s\n",
      "Epoch 41 - Accuracy: 0.6335877862595419\n",
      "Epoch 41 - Best Score: 0.6336\n",
      "Epoch 42 - avg_train_loss: 1.7682  avg_val_loss: 2.1922  time: 69s\n",
      "Epoch 42 - Accuracy: 0.6412213740458015\n",
      "Epoch 42 - Best Score: 0.6412\n",
      "Epoch 43 - avg_train_loss: 1.7675  avg_val_loss: 2.1892  time: 70s\n",
      "Epoch 43 - Accuracy: 0.6183206106870229\n",
      "Epoch 43 - Best Score: 0.6412\n",
      "Epoch 44 - avg_train_loss: 1.7768  avg_val_loss: 2.1755  time: 69s\n",
      "Epoch 44 - Accuracy: 0.6259541984732825\n",
      "Epoch 44 - Best Score: 0.6412\n",
      "Epoch 45 - avg_train_loss: 1.7759  avg_val_loss: 2.1893  time: 69s\n",
      "Epoch 45 - Accuracy: 0.6030534351145038\n",
      "Epoch 45 - Best Score: 0.6412\n",
      "Epoch 46 - avg_train_loss: 1.7769  avg_val_loss: 2.1684  time: 69s\n",
      "Epoch 46 - Accuracy: 0.5877862595419847\n",
      "Epoch 46 - Best Score: 0.6412\n",
      "Epoch 47 - avg_train_loss: 1.7752  avg_val_loss: 2.1652  time: 69s\n",
      "Epoch 47 - Accuracy: 0.6106870229007634\n",
      "Epoch 47 - Best Score: 0.6412\n",
      "Epoch 48 - avg_train_loss: 1.7732  avg_val_loss: 2.1843  time: 70s\n",
      "Epoch 48 - Accuracy: 0.5801526717557252\n",
      "Epoch 48 - Best Score: 0.6412\n",
      "Epoch 49 - avg_train_loss: 1.7713  avg_val_loss: 2.1851  time: 70s\n",
      "Epoch 49 - Accuracy: 0.6106870229007634\n",
      "Epoch 49 - Best Score: 0.6412\n",
      "Epoch 50 - avg_train_loss: 1.7748  avg_val_loss: 2.1831  time: 69s\n",
      "Epoch 50 - Accuracy: 0.5954198473282443\n",
      "Epoch 50 - Best Score: 0.6412\n",
      "Epoch 51 - avg_train_loss: 1.7714  avg_val_loss: 2.1761  time: 69s\n",
      "Epoch 51 - Accuracy: 0.6259541984732825\n",
      "Epoch 51 - Best Score: 0.6412\n",
      "Epoch 52 - avg_train_loss: 1.7733  avg_val_loss: 2.1646  time: 69s\n",
      "Epoch 52 - Accuracy: 0.6183206106870229\n",
      "Epoch 52 - Best Score: 0.6412\n",
      "Epoch 53 - avg_train_loss: 1.7770  avg_val_loss: 2.1719  time: 69s\n",
      "Epoch 53 - Accuracy: 0.6259541984732825\n",
      "Epoch 53 - Best Score: 0.6412\n",
      "Epoch 54 - avg_train_loss: 1.7706  avg_val_loss: 2.2005  time: 69s\n",
      "Epoch 54 - Accuracy: 0.5725190839694656\n",
      "Epoch 54 - Best Score: 0.6412\n",
      "Epoch 55 - avg_train_loss: 1.7700  avg_val_loss: 2.1888  time: 69s\n",
      "Epoch 55 - Accuracy: 0.6183206106870229\n",
      "Epoch 55 - Best Score: 0.6412\n",
      "Epoch 56 - avg_train_loss: 1.7817  avg_val_loss: 2.1848  time: 69s\n",
      "Epoch 56 - Accuracy: 0.5954198473282443\n",
      "Epoch 56 - Best Score: 0.6412\n",
      "Epoch 57 - avg_train_loss: 1.7819  avg_val_loss: 2.1897  time: 69s\n",
      "Epoch 57 - Accuracy: 0.5572519083969466\n",
      "Epoch 57 - Best Score: 0.6412\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 58 - avg_train_loss: 1.7733  avg_val_loss: 2.1874  time: 70s\n",
      "Epoch 58 - Accuracy: 0.5954198473282443\n",
      "Epoch 58 - Best Score: 0.6412\n",
      "Epoch 59 - avg_train_loss: 1.7684  avg_val_loss: 2.1906  time: 70s\n",
      "Epoch 59 - Accuracy: 0.5877862595419847\n",
      "Epoch 59 - Best Score: 0.6412\n",
      "Epoch 60 - avg_train_loss: 1.7702  avg_val_loss: 2.1949  time: 69s\n",
      "Epoch 60 - Accuracy: 0.5725190839694656\n",
      "Epoch 60 - Best Score: 0.6412\n",
      "Epoch 61 - avg_train_loss: 1.7738  avg_val_loss: 2.1790  time: 70s\n",
      "Epoch 61 - Accuracy: 0.5877862595419847\n",
      "Epoch 61 - Best Score: 0.6412\n",
      "Epoch 62 - avg_train_loss: 1.7739  avg_val_loss: 2.1716  time: 69s\n",
      "Epoch 62 - Accuracy: 0.6183206106870229\n",
      "Epoch 62 - Best Score: 0.6412\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 2 result ==========\n",
      "Score: 0.64122\n",
      "fold: 3\n",
      "Epoch 1 - avg_train_loss: 2.5579  avg_val_loss: 2.5555  time: 69s\n",
      "Epoch 1 - Accuracy: 0.13740458015267176\n",
      "Epoch 1 - Best Score: 0.1374\n",
      "Epoch 2 - avg_train_loss: 2.5097  avg_val_loss: 2.4987  time: 70s\n",
      "Epoch 2 - Accuracy: 0.16793893129770993\n",
      "Epoch 2 - Best Score: 0.1679\n",
      "Epoch 3 - avg_train_loss: 2.4322  avg_val_loss: 2.4600  time: 70s\n",
      "Epoch 3 - Accuracy: 0.2900763358778626\n",
      "Epoch 3 - Best Score: 0.2901\n",
      "Epoch 4 - avg_train_loss: 2.3559  avg_val_loss: 2.4132  time: 70s\n",
      "Epoch 4 - Accuracy: 0.31297709923664124\n",
      "Epoch 4 - Best Score: 0.3130\n",
      "Epoch 5 - avg_train_loss: 2.2805  avg_val_loss: 2.3619  time: 69s\n",
      "Epoch 5 - Accuracy: 0.3893129770992366\n",
      "Epoch 5 - Best Score: 0.3893\n",
      "Epoch 6 - avg_train_loss: 2.2176  avg_val_loss: 2.3640  time: 69s\n",
      "Epoch 6 - Accuracy: 0.37404580152671757\n",
      "Epoch 6 - Best Score: 0.3893\n",
      "Epoch 7 - avg_train_loss: 2.1466  avg_val_loss: 2.3660  time: 70s\n",
      "Epoch 7 - Accuracy: 0.3893129770992366\n",
      "Epoch 7 - Best Score: 0.3893\n",
      "Epoch 8 - avg_train_loss: 2.1038  avg_val_loss: 2.3412  time: 69s\n",
      "Epoch 8 - Accuracy: 0.42748091603053434\n",
      "Epoch 8 - Best Score: 0.4275\n",
      "Epoch 9 - avg_train_loss: 2.0603  avg_val_loss: 2.3116  time: 70s\n",
      "Epoch 9 - Accuracy: 0.4732824427480916\n",
      "Epoch 9 - Best Score: 0.4733\n",
      "Epoch 10 - avg_train_loss: 2.0180  avg_val_loss: 2.3057  time: 69s\n",
      "Epoch 10 - Accuracy: 0.4732824427480916\n",
      "Epoch 10 - Best Score: 0.4733\n",
      "Epoch 11 - avg_train_loss: 1.9876  avg_val_loss: 2.2693  time: 70s\n",
      "Epoch 11 - Accuracy: 0.5343511450381679\n",
      "Epoch 11 - Best Score: 0.5344\n",
      "Epoch 12 - avg_train_loss: 1.9673  avg_val_loss: 2.3029  time: 70s\n",
      "Epoch 12 - Accuracy: 0.5038167938931297\n",
      "Epoch 12 - Best Score: 0.5344\n",
      "Epoch 13 - avg_train_loss: 1.9524  avg_val_loss: 2.2827  time: 69s\n",
      "Epoch 13 - Accuracy: 0.5343511450381679\n",
      "Epoch 13 - Best Score: 0.5344\n",
      "Epoch 14 - avg_train_loss: 1.9348  avg_val_loss: 2.3086  time: 69s\n",
      "Epoch 14 - Accuracy: 0.45038167938931295\n",
      "Epoch 14 - Best Score: 0.5344\n",
      "Epoch 15 - avg_train_loss: 1.9235  avg_val_loss: 2.2341  time: 69s\n",
      "Epoch 15 - Accuracy: 0.5801526717557252\n",
      "Epoch 15 - Best Score: 0.5802\n",
      "Epoch 16 - avg_train_loss: 1.8887  avg_val_loss: 2.2572  time: 70s\n",
      "Epoch 16 - Accuracy: 0.549618320610687\n",
      "Epoch 16 - Best Score: 0.5802\n",
      "Epoch 17 - avg_train_loss: 1.8739  avg_val_loss: 2.2552  time: 69s\n",
      "Epoch 17 - Accuracy: 0.5343511450381679\n",
      "Epoch 17 - Best Score: 0.5802\n",
      "Epoch 18 - avg_train_loss: 1.8729  avg_val_loss: 2.2700  time: 69s\n",
      "Epoch 18 - Accuracy: 0.5114503816793893\n",
      "Epoch 18 - Best Score: 0.5802\n",
      "Epoch 19 - avg_train_loss: 1.8580  avg_val_loss: 2.2603  time: 69s\n",
      "Epoch 19 - Accuracy: 0.5038167938931297\n",
      "Epoch 19 - Best Score: 0.5802\n",
      "Epoch 20 - avg_train_loss: 1.8471  avg_val_loss: 2.2539  time: 69s\n",
      "Epoch 20 - Accuracy: 0.5114503816793893\n",
      "Epoch 20 - Best Score: 0.5802\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 21 - avg_train_loss: 1.8456  avg_val_loss: 2.2561  time: 70s\n",
      "Epoch 21 - Accuracy: 0.549618320610687\n",
      "Epoch 21 - Best Score: 0.5802\n",
      "Epoch 22 - avg_train_loss: 1.8388  avg_val_loss: 2.2390  time: 69s\n",
      "Epoch 22 - Accuracy: 0.5343511450381679\n",
      "Epoch 22 - Best Score: 0.5802\n",
      "Epoch 23 - avg_train_loss: 1.8416  avg_val_loss: 2.2342  time: 69s\n",
      "Epoch 23 - Accuracy: 0.549618320610687\n",
      "Epoch 23 - Best Score: 0.5802\n",
      "Epoch 24 - avg_train_loss: 1.8276  avg_val_loss: 2.2347  time: 69s\n",
      "Epoch 24 - Accuracy: 0.5725190839694656\n",
      "Epoch 24 - Best Score: 0.5802\n",
      "Epoch 25 - avg_train_loss: 1.8304  avg_val_loss: 2.2326  time: 69s\n",
      "Epoch 25 - Accuracy: 0.5267175572519084\n",
      "Epoch 25 - Best Score: 0.5802\n",
      "Epoch 26 - avg_train_loss: 1.8216  avg_val_loss: 2.2512  time: 69s\n",
      "Epoch 26 - Accuracy: 0.5648854961832062\n",
      "Epoch 26 - Best Score: 0.5802\n",
      "Epoch 27 - avg_train_loss: 1.8175  avg_val_loss: 2.2476  time: 69s\n",
      "Epoch 27 - Accuracy: 0.5267175572519084\n",
      "Epoch 27 - Best Score: 0.5802\n",
      "Epoch 28 - avg_train_loss: 1.8150  avg_val_loss: 2.2233  time: 69s\n",
      "Epoch 28 - Accuracy: 0.5419847328244275\n",
      "Epoch 28 - Best Score: 0.5802\n",
      "Epoch 29 - avg_train_loss: 1.8107  avg_val_loss: 2.2194  time: 69s\n",
      "Epoch 29 - Accuracy: 0.5648854961832062\n",
      "Epoch 29 - Best Score: 0.5802\n",
      "Epoch 30 - avg_train_loss: 1.8186  avg_val_loss: 2.2234  time: 69s\n",
      "Epoch 30 - Accuracy: 0.5648854961832062\n",
      "Epoch 30 - Best Score: 0.5802\n",
      "Epoch 31 - avg_train_loss: 1.8212  avg_val_loss: 2.2454  time: 69s\n",
      "Epoch 31 - Accuracy: 0.5419847328244275\n",
      "Epoch 31 - Best Score: 0.5802\n",
      "Epoch 32 - avg_train_loss: 1.8155  avg_val_loss: 2.2256  time: 69s\n",
      "Epoch 32 - Accuracy: 0.5572519083969466\n",
      "Epoch 32 - Best Score: 0.5802\n",
      "Epoch 33 - avg_train_loss: 1.8161  avg_val_loss: 2.2281  time: 69s\n",
      "Epoch 33 - Accuracy: 0.5572519083969466\n",
      "Epoch 33 - Best Score: 0.5802\n",
      "Epoch 34 - avg_train_loss: 1.8180  avg_val_loss: 2.2300  time: 69s\n",
      "Epoch 34 - Accuracy: 0.5572519083969466\n",
      "Epoch 34 - Best Score: 0.5802\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 35 - avg_train_loss: 1.8183  avg_val_loss: 2.2258  time: 69s\n",
      "Epoch 35 - Accuracy: 0.5648854961832062\n",
      "Epoch 35 - Best Score: 0.5802\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 3 result ==========\n",
      "Score: 0.58015\n",
      "fold: 4\n",
      "Epoch 1 - avg_train_loss: 2.5573  avg_val_loss: 2.5528  time: 69s\n",
      "Epoch 1 - Accuracy: 0.24615384615384617\n",
      "Epoch 1 - Best Score: 0.2462\n",
      "Epoch 2 - avg_train_loss: 2.5210  avg_val_loss: 2.5151  time: 69s\n",
      "Epoch 2 - Accuracy: 0.2692307692307692\n",
      "Epoch 2 - Best Score: 0.2692\n",
      "Epoch 3 - avg_train_loss: 2.4351  avg_val_loss: 2.4336  time: 69s\n",
      "Epoch 3 - Accuracy: 0.36923076923076925\n",
      "Epoch 3 - Best Score: 0.3692\n",
      "Epoch 4 - avg_train_loss: 2.3488  avg_val_loss: 2.3842  time: 69s\n",
      "Epoch 4 - Accuracy: 0.4230769230769231\n",
      "Epoch 4 - Best Score: 0.4231\n",
      "Epoch 5 - avg_train_loss: 2.2674  avg_val_loss: 2.3127  time: 69s\n",
      "Epoch 5 - Accuracy: 0.49230769230769234\n",
      "Epoch 5 - Best Score: 0.4923\n",
      "Epoch 6 - avg_train_loss: 2.1974  avg_val_loss: 2.3011  time: 69s\n",
      "Epoch 6 - Accuracy: 0.5307692307692308\n",
      "Epoch 6 - Best Score: 0.5308\n",
      "Epoch 7 - avg_train_loss: 2.1647  avg_val_loss: 2.3026  time: 69s\n",
      "Epoch 7 - Accuracy: 0.4461538461538462\n",
      "Epoch 7 - Best Score: 0.5308\n",
      "Epoch 8 - avg_train_loss: 2.1058  avg_val_loss: 2.2915  time: 69s\n",
      "Epoch 8 - Accuracy: 0.46153846153846156\n",
      "Epoch 8 - Best Score: 0.5308\n",
      "Epoch 9 - avg_train_loss: 2.0646  avg_val_loss: 2.2792  time: 69s\n",
      "Epoch 9 - Accuracy: 0.49230769230769234\n",
      "Epoch 9 - Best Score: 0.5308\n",
      "Epoch 10 - avg_train_loss: 2.0231  avg_val_loss: 2.2562  time: 69s\n",
      "Epoch 10 - Accuracy: 0.46923076923076923\n",
      "Epoch 10 - Best Score: 0.5308\n",
      "Epoch 11 - avg_train_loss: 2.0085  avg_val_loss: 2.2464  time: 69s\n",
      "Epoch 11 - Accuracy: 0.4461538461538462\n",
      "Epoch 11 - Best Score: 0.5308\n",
      "Epoch 12 - avg_train_loss: 1.9664  avg_val_loss: 2.2321  time: 69s\n",
      "Epoch 12 - Accuracy: 0.46153846153846156\n",
      "Epoch 12 - Best Score: 0.5308\n",
      "Epoch 13 - avg_train_loss: 1.9391  avg_val_loss: 2.2486  time: 69s\n",
      "Epoch 13 - Accuracy: 0.5230769230769231\n",
      "Epoch 13 - Best Score: 0.5308\n",
      "Epoch 14 - avg_train_loss: 1.9163  avg_val_loss: 2.2522  time: 69s\n",
      "Epoch 14 - Accuracy: 0.5076923076923077\n",
      "Epoch 14 - Best Score: 0.5308\n",
      "Epoch 15 - avg_train_loss: 1.9118  avg_val_loss: 2.2494  time: 69s\n",
      "Epoch 15 - Accuracy: 0.4846153846153846\n",
      "Epoch 15 - Best Score: 0.5308\n",
      "Epoch 16 - avg_train_loss: 1.8910  avg_val_loss: 2.2720  time: 69s\n",
      "Epoch 16 - Accuracy: 0.49230769230769234\n",
      "Epoch 16 - Best Score: 0.5308\n",
      "Epoch 17 - avg_train_loss: 1.8907  avg_val_loss: 2.2263  time: 69s\n",
      "Epoch 17 - Accuracy: 0.5\n",
      "Epoch 17 - Best Score: 0.5308\n",
      "Epoch 18 - avg_train_loss: 1.8830  avg_val_loss: 2.2329  time: 69s\n",
      "Epoch 18 - Accuracy: 0.5307692307692308\n",
      "Epoch 18 - Best Score: 0.5308\n",
      "Epoch 19 - avg_train_loss: 1.8655  avg_val_loss: 2.2273  time: 69s\n",
      "Epoch 19 - Accuracy: 0.5076923076923077\n",
      "Epoch 19 - Best Score: 0.5308\n",
      "Epoch 20 - avg_train_loss: 1.8589  avg_val_loss: 2.2329  time: 69s\n",
      "Epoch 20 - Accuracy: 0.5615384615384615\n",
      "Epoch 20 - Best Score: 0.5615\n",
      "Epoch 21 - avg_train_loss: 1.8468  avg_val_loss: 2.2690  time: 69s\n",
      "Epoch 21 - Accuracy: 0.5076923076923077\n",
      "Epoch 21 - Best Score: 0.5615\n",
      "Epoch 22 - avg_train_loss: 1.8496  avg_val_loss: 2.2120  time: 69s\n",
      "Epoch 22 - Accuracy: 0.5384615384615384\n",
      "Epoch 22 - Best Score: 0.5615\n",
      "Epoch 23 - avg_train_loss: 1.8467  avg_val_loss: 2.2175  time: 69s\n",
      "Epoch 23 - Accuracy: 0.5461538461538461\n",
      "Epoch 23 - Best Score: 0.5615\n",
      "Epoch 24 - avg_train_loss: 1.8262  avg_val_loss: 2.2198  time: 69s\n",
      "Epoch 24 - Accuracy: 0.5076923076923077\n",
      "Epoch 24 - Best Score: 0.5615\n",
      "Epoch 25 - avg_train_loss: 1.8323  avg_val_loss: 2.2346  time: 69s\n",
      "Epoch 25 - Accuracy: 0.5153846153846153\n",
      "Epoch 25 - Best Score: 0.5615\n",
      "Epoch 26 - avg_train_loss: 1.8121  avg_val_loss: 2.2443  time: 69s\n",
      "Epoch 26 - Accuracy: 0.47692307692307695\n",
      "Epoch 26 - Best Score: 0.5615\n",
      "Epoch 27 - avg_train_loss: 1.8191  avg_val_loss: 2.2189  time: 69s\n",
      "Epoch 27 - Accuracy: 0.5384615384615384\n",
      "Epoch 27 - Best Score: 0.5615\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 28 - avg_train_loss: 1.8086  avg_val_loss: 2.2224  time: 69s\n",
      "Epoch 28 - Accuracy: 0.5307692307692308\n",
      "Epoch 28 - Best Score: 0.5615\n",
      "Epoch 29 - avg_train_loss: 1.7986  avg_val_loss: 2.2078  time: 69s\n",
      "Epoch 29 - Accuracy: 0.5461538461538461\n",
      "Epoch 29 - Best Score: 0.5615\n",
      "Epoch 30 - avg_train_loss: 1.7973  avg_val_loss: 2.2043  time: 69s\n",
      "Epoch 30 - Accuracy: 0.5538461538461539\n",
      "Epoch 30 - Best Score: 0.5615\n",
      "Epoch 31 - avg_train_loss: 1.7996  avg_val_loss: 2.2037  time: 69s\n",
      "Epoch 31 - Accuracy: 0.5384615384615384\n",
      "Epoch 31 - Best Score: 0.5615\n",
      "Epoch 32 - avg_train_loss: 1.8047  avg_val_loss: 2.2181  time: 69s\n",
      "Epoch 32 - Accuracy: 0.5384615384615384\n",
      "Epoch 32 - Best Score: 0.5615\n",
      "Epoch 33 - avg_train_loss: 1.8077  avg_val_loss: 2.2149  time: 69s\n",
      "Epoch 33 - Accuracy: 0.5615384615384615\n",
      "Epoch 33 - Best Score: 0.5615\n",
      "Epoch 34 - avg_train_loss: 1.7879  avg_val_loss: 2.2184  time: 69s\n",
      "Epoch 34 - Accuracy: 0.5384615384615384\n",
      "Epoch 34 - Best Score: 0.5615\n",
      "Epoch 35 - avg_train_loss: 1.8094  avg_val_loss: 2.2028  time: 69s\n",
      "Epoch 35 - Accuracy: 0.5692307692307692\n",
      "Epoch 35 - Best Score: 0.5692\n",
      "Epoch 36 - avg_train_loss: 1.7879  avg_val_loss: 2.2016  time: 69s\n",
      "Epoch 36 - Accuracy: 0.5461538461538461\n",
      "Epoch 36 - Best Score: 0.5692\n",
      "Epoch 37 - avg_train_loss: 1.7935  avg_val_loss: 2.2308  time: 69s\n",
      "Epoch 37 - Accuracy: 0.5\n",
      "Epoch 37 - Best Score: 0.5692\n",
      "Epoch 38 - avg_train_loss: 1.7975  avg_val_loss: 2.2108  time: 69s\n",
      "Epoch 38 - Accuracy: 0.5461538461538461\n",
      "Epoch 38 - Best Score: 0.5692\n",
      "Epoch 39 - avg_train_loss: 1.7853  avg_val_loss: 2.2058  time: 69s\n",
      "Epoch 39 - Accuracy: 0.5384615384615384\n",
      "Epoch 39 - Best Score: 0.5692\n",
      "Epoch 40 - avg_train_loss: 1.7895  avg_val_loss: 2.2047  time: 69s\n",
      "Epoch 40 - Accuracy: 0.5307692307692308\n",
      "Epoch 40 - Best Score: 0.5692\n",
      "Epoch 41 - avg_train_loss: 1.7931  avg_val_loss: 2.2269  time: 69s\n",
      "Epoch 41 - Accuracy: 0.5538461538461539\n",
      "Epoch 41 - Best Score: 0.5692\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 42 - avg_train_loss: 1.7904  avg_val_loss: 2.2095  time: 69s\n",
      "Epoch 42 - Accuracy: 0.5307692307692308\n",
      "Epoch 42 - Best Score: 0.5692\n",
      "Epoch 43 - avg_train_loss: 1.7830  avg_val_loss: 2.2024  time: 69s\n",
      "Epoch 43 - Accuracy: 0.5538461538461539\n",
      "Epoch 43 - Best Score: 0.5692\n",
      "Epoch 44 - avg_train_loss: 1.7922  avg_val_loss: 2.2074  time: 69s\n",
      "Epoch 44 - Accuracy: 0.5461538461538461\n",
      "Epoch 44 - Best Score: 0.5692\n",
      "Epoch 45 - avg_train_loss: 1.8002  avg_val_loss: 2.1739  time: 69s\n",
      "Epoch 45 - Accuracy: 0.5538461538461539\n",
      "Epoch 45 - Best Score: 0.5692\n",
      "Epoch 46 - avg_train_loss: 1.7948  avg_val_loss: 2.2193  time: 69s\n",
      "Epoch 46 - Accuracy: 0.5615384615384615\n",
      "Epoch 46 - Best Score: 0.5692\n",
      "Epoch 47 - avg_train_loss: 1.7891  avg_val_loss: 2.2020  time: 69s\n",
      "Epoch 47 - Accuracy: 0.5769230769230769\n",
      "Epoch 47 - Best Score: 0.5769\n",
      "Epoch 48 - avg_train_loss: 1.7908  avg_val_loss: 2.2218  time: 69s\n",
      "Epoch 48 - Accuracy: 0.5230769230769231\n",
      "Epoch 48 - Best Score: 0.5769\n",
      "Epoch 49 - avg_train_loss: 1.7875  avg_val_loss: 2.2091  time: 69s\n",
      "Epoch 49 - Accuracy: 0.5615384615384615\n",
      "Epoch 49 - Best Score: 0.5769\n",
      "Epoch 50 - avg_train_loss: 1.7819  avg_val_loss: 2.2192  time: 69s\n",
      "Epoch 50 - Accuracy: 0.5461538461538461\n",
      "Epoch 50 - Best Score: 0.5769\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch 51 - avg_train_loss: 1.7865  avg_val_loss: 2.2078  time: 69s\n",
      "Epoch 51 - Accuracy: 0.5384615384615384\n",
      "Epoch 51 - Best Score: 0.5769\n",
      "Epoch 52 - avg_train_loss: 1.7911  avg_val_loss: 2.2058  time: 69s\n",
      "Epoch 52 - Accuracy: 0.5461538461538461\n",
      "Epoch 52 - Best Score: 0.5769\n",
      "Epoch 53 - avg_train_loss: 1.7903  avg_val_loss: 2.2111  time: 69s\n",
      "Epoch 53 - Accuracy: 0.5153846153846153\n",
      "Epoch 53 - Best Score: 0.5769\n",
      "Epoch 54 - avg_train_loss: 1.7941  avg_val_loss: 2.2072  time: 69s\n",
      "Epoch 54 - Accuracy: 0.5615384615384615\n",
      "Epoch 54 - Best Score: 0.5769\n",
      "Epoch 55 - avg_train_loss: 1.7955  avg_val_loss: 2.2116  time: 69s\n",
      "Epoch 55 - Accuracy: 0.5692307692307692\n",
      "Epoch 55 - Best Score: 0.5769\n",
      "Epoch 56 - avg_train_loss: 1.7918  avg_val_loss: 2.2036  time: 69s\n",
      "Epoch 56 - Accuracy: 0.5461538461538461\n",
      "Epoch 56 - Best Score: 0.5769\n",
      "Epoch 57 - avg_train_loss: 1.7905  avg_val_loss: 2.2078  time: 69s\n",
      "Epoch 57 - Accuracy: 0.5538461538461539\n",
      "Epoch 57 - Best Score: 0.5769\n",
      "Epoch 58 - avg_train_loss: 1.7930  avg_val_loss: 2.2124  time: 69s\n",
      "Epoch 58 - Accuracy: 0.5461538461538461\n",
      "Epoch 58 - Best Score: 0.5769\n",
      "Epoch 59 - avg_train_loss: 1.7981  avg_val_loss: 2.2120  time: 69s\n",
      "Epoch 59 - Accuracy: 0.5769230769230769\n",
      "Epoch 59 - Best Score: 0.5769\n",
      "Epoch 60 - avg_train_loss: 1.7761  avg_val_loss: 2.2088  time: 69s\n",
      "Epoch 60 - Accuracy: 0.5538461538461539\n",
      "Epoch 60 - Best Score: 0.5769\n",
      "Epoch 61 - avg_train_loss: 1.7867  avg_val_loss: 2.1914  time: 69s\n",
      "Epoch 61 - Accuracy: 0.5384615384615384\n",
      "Epoch 61 - Best Score: 0.5769\n",
      "Epoch 62 - avg_train_loss: 1.7850  avg_val_loss: 2.2128  time: 69s\n",
      "Epoch 62 - Accuracy: 0.5615384615384615\n",
      "Epoch 62 - Best Score: 0.5769\n",
      "Epoch 63 - avg_train_loss: 1.7869  avg_val_loss: 2.2087  time: 69s\n",
      "Epoch 63 - Accuracy: 0.5538461538461539\n",
      "Epoch 63 - Best Score: 0.5769\n",
      "Epoch 64 - avg_train_loss: 1.7911  avg_val_loss: 2.2227  time: 69s\n",
      "Epoch 64 - Accuracy: 0.5230769230769231\n",
      "Epoch 64 - Best Score: 0.5769\n",
      "Epoch 65 - avg_train_loss: 1.7900  avg_val_loss: 2.2048  time: 69s\n",
      "Epoch 65 - Accuracy: 0.5384615384615384\n",
      "Epoch 65 - Best Score: 0.5769\n",
      "Epoch 66 - avg_train_loss: 1.7909  avg_val_loss: 2.2104  time: 69s\n",
      "Epoch 66 - Accuracy: 0.5461538461538461\n",
      "Epoch 66 - Best Score: 0.5769\n",
      "Epoch 67 - avg_train_loss: 1.7866  avg_val_loss: 2.2002  time: 69s\n",
      "Epoch 67 - Accuracy: 0.5461538461538461\n",
      "Epoch 67 - Best Score: 0.5769\n",
      "Early stopping break: not improved 20 times in a row\n",
      "========== fold: 4 result ==========\n",
      "Score: 0.57692\n",
      "========== CV ==========\n",
      "Score: 0.58716\n",
      "CPU times: user 13h 46min 53s, sys: 1h 19min 56s, total: 15h 6min 49s\n",
      "Wall time: 4h 59min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TrainRunner(model_config).run_cv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba9ba8b-317b-42a0-9a0b-c6bd8e07f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  fold  preds\n",
       "0         5     0      5\n",
       "1         6     0      6\n",
       "2         4     0      5\n",
       "3         7     0      7\n",
       "4         0     0      0\n",
       "..      ...   ...    ...\n",
       "125       3     4      3\n",
       "126      11     4     11\n",
       "127       5     4      2\n",
       "128       9     4      9\n",
       "129       2     4      2\n",
       "\n",
       "[654 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _oof_df = Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")\n",
    "# print(\"========== CV ==========\")\n",
    "# TrainRunner(model_config)._evaluate(_oof_df[\"target\"], _oof_df[\"preds\"], verbose=True)\n",
    "\n",
    "Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e174df-3c50-4bae-a0be-dc59445ea40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train_labels, label=\"true\")\n",
    "plt.show()\n",
    "sns.countplot(x=Jbl.load(f\"{OutputPath.model}/oof_df_{model_config.basic.run_name}.jbl\")[\"preds\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2e35b9-f7b8-4ea9-96e4-6053d8dc537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "fold: 1\n",
      "fold: 2\n",
      "fold: 3\n",
      "fold: 4\n",
      "   id   y\n",
      "0   0   2\n",
      "1   1   4\n",
      "2   2  10\n",
      "3   3   3\n",
      "4   4   1\n",
      "submission.csv created\n"
     ]
    }
   ],
   "source": [
    "InferenceRunner(model_config).run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac819026-9e1b-4dd7-b02d-c0cecfeff158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
